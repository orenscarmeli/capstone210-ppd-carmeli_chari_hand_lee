{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add annotations describing usage of different modules\n",
    "\n",
    "from operator import mod\n",
    "from os import getcwd\n",
    "from os.path import exists, join\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, KBinsDiscretizer\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from ydata_profiling import ProfileReport\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "# import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import pickle\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "import altair as alt\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set seaborn whitegrid theme\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from random import sample\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(original_df, \n",
    "                   columns, \n",
    "                   test_size_to_use=0.2,\n",
    "                   drop_null_rows=False,\n",
    "                   null_imputer_strategy='median', # mean, median, most_frequent\n",
    "                   use_value_scaler=True,\n",
    "                   use_smote=False,\n",
    "                   return_indices=False):\n",
    "    \"\"\"\n",
    "    Function to build feature & indicator matrices for both train & test.\n",
    "    \"\"\"\n",
    "    \n",
    "    # add target column (MDD)\n",
    "    cols_to_use = columns.copy()\n",
    "    cols_to_use.insert(0, 'MDD')\n",
    "    #cols_to_use.insert(0, 'SEQN')\n",
    "    \n",
    "    df_to_use = original_df[cols_to_use]\n",
    "    \n",
    "    if drop_null_rows:\n",
    "        df_to_use.dropna(inplace=True)\n",
    "    \n",
    "    # Create test & train data\n",
    "    x = df_to_use.iloc[:,1:].values\n",
    "    y = df_to_use['MDD'].values\n",
    "    indices = np.arange(y.shape[0])\n",
    "    \n",
    "    if not drop_null_rows:\n",
    "        # SimpleImputer() = fill in missing values\n",
    "        # note imputer may drop columns if no values exist for it\n",
    "        imputer = SimpleImputer(strategy=null_imputer_strategy)  \n",
    "        x = imputer.fit_transform(x)\n",
    "\n",
    "    # RobustScaler() = scale features to remove outliers\n",
    "    if use_value_scaler:\n",
    "        trans = RobustScaler()\n",
    "        x = trans.fit_transform(x)\n",
    "\n",
    "    x_train, x_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "        x, \n",
    "        y, \n",
    "        indices,\n",
    "        test_size=test_size_to_use, \n",
    "        random_state=42\n",
    "    ) \n",
    "    \n",
    "    # Technique to de-risk from positive class imbalance\n",
    "    if use_smote:\n",
    "        sm = SMOTE(random_state=42)\n",
    "        x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "    \n",
    "    if return_indices:\n",
    "        return x_train, x_test, y_train, y_test, idx_train, idx_test\n",
    "    else:\n",
    "        return x_train, x_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "def get_performance_df(label_actual, label_pred, model_name):\n",
    "    \"\"\"\n",
    "    Function to calculate performance metrics for model.\n",
    "    Includes precision, recal, F1, & support.\n",
    "    \"\"\"\n",
    "    # create classification report\n",
    "    result_table = classification_report(label_actual, label_pred, output_dict=True)\n",
    "    result_table = pd.DataFrame.from_dict(result_table)\n",
    "\n",
    "    # store for later\n",
    "    accuracies = result_table['accuracy'][0]\n",
    "    \n",
    "    column_key = {\n",
    "        '0':'Depressed (No)',\n",
    "         '1':'Depressed (Yes)',\n",
    "         'accuracy':'accuracy',\n",
    "         'macro avg':'Macro Avg',\n",
    "         'weighted avg':'Weighted Avg'\n",
    "    }\n",
    "\n",
    "    # rename grouping\n",
    "    result_table.columns = [column_key.get(key) for key in result_table.columns]\n",
    "\n",
    "    # create dataframe with 1 row per grouping\n",
    "    result_table.drop(labels = 'accuracy', axis = 1, inplace=True)\n",
    "    result_table = result_table.transpose()\n",
    "    result_table['accuracy'] = [accuracies for i in range(result_table.shape[0])]\n",
    "    result_table = result_table.reset_index()\n",
    "    result_table.rename(columns = {'index':'grouping'},inplace=True)\n",
    "    result_table['model'] = model_name\n",
    "    result_table = result_table[['model','grouping','precision','recall','f1-score','support','accuracy']]\n",
    "    return result_table    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35706, 863)\n",
      "(7741, 864)\n"
     ]
    }
   ],
   "source": [
    "cdc_survey = pd.read_csv('../../../data/cdc_nhanes_survey_responses_clean.csv')\n",
    "print(cdc_survey.shape)\n",
    "\n",
    "# filter to pregnant moms\n",
    "cdc_survey_pmom = cdc_survey[cdc_survey['has_been_pregnant'] == 1].reset_index()\n",
    "print(cdc_survey_pmom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create subset datasets \n",
    "- cdc_survey_pmom_1plus_dep_screener = 1+ dep screener above 0\n",
    "- cdc_survey_pmom_0dep_screener = 0 dep screener above 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4394, 868)\n",
      "(3347, 868)\n"
     ]
    }
   ],
   "source": [
    "dep_screener_cols = [\n",
    "    'little_interest_in_doing_things',\n",
    "    'feeling_down_depressed_hopeless',\n",
    "    'trouble_falling_or_staying_asleep',\n",
    "    'feeling_tired_or_having_little_energy',\n",
    "    'poor_appetitie_or_overeating',\n",
    "    'feeling_bad_about_yourself',\n",
    "    'trouble_concentrating',\n",
    "    'moving_or_speaking_to_slowly_or_fast',\n",
    "    'thoughts_you_would_be_better_off_dead',\n",
    "    'difficult_doing_daytoday_tasks'\n",
    "]\n",
    "\n",
    "cdc_survey_pmom['num_dep_screener_0'] = (cdc_survey_pmom[dep_screener_cols]==0).sum(axis=1)\n",
    "cdc_survey_pmom['num_dep_screener_nonzero'] = (cdc_survey_pmom[dep_screener_cols]>0).sum(axis=1)\n",
    "cdc_survey_pmom['num_dep_screener_null'] = cdc_survey_pmom[dep_screener_cols].isnull().sum(axis=1)\n",
    "cdc_survey_pmom['weight_lbs_over_height_in_ratio'] = round(cdc_survey_pmom['weight_lbs'] / cdc_survey_pmom['height_in'],1)\n",
    "\n",
    "cdc_survey_pmom_1plus_dep_screener = cdc_survey_pmom[cdc_survey_pmom['num_dep_screener_0'] < 9]\n",
    "#cdc_survey_pmom_1plus_dep_screener = cdc_survey_pmom[cdc_survey_pmom['num_dep_screener_nonzero'] >= 1]\n",
    "print(cdc_survey_pmom_1plus_dep_screener.shape)\n",
    "\n",
    "cdc_survey_pmom_0dep_screener = cdc_survey_pmom[cdc_survey_pmom['num_dep_screener_0'] >= 9]\n",
    "#cdc_survey_pmom_0dep_screener = cdc_survey_pmom[cdc_survey_pmom['num_dep_screener_nonzero'] == 0]\n",
    "print(cdc_survey_pmom_0dep_screener.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNB Classifier (train & predict on cdc_survey_pmom_1plus_dep_screener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_survey_pmom_1plus_dep_screener['weight_lbs_over_height_in_ratio'] = round(cdc_survey_pmom_1plus_dep_screener['weight_lbs'] / cdc_survey_pmom_1plus_dep_screener['height_in'],1)\n",
    "\n",
    "gnb_model_features = dep_screener_cols + ['seen_mental_health_professional',\n",
    " 'times_with_12plus_alc',\n",
    " 'time_since_last_healthcare',\n",
    " 'cholesterol_prescription',\n",
    " 'high_cholesterol',\n",
    " 'age_in_years',\n",
    " 'horomones_not_bc',\n",
    " 'months_since_birth',\n",
    " 'arthritis',\n",
    " 'high_bp',\n",
    " 'regular_periods',\n",
    " 'moderate_recreation',\n",
    " 'thyroid_issues',\n",
    " 'vigorous_recreation',\n",
    " 'stroke',\n",
    " 'is_usa_born',\n",
    " 'asthma',\n",
    " 'count_days_moderate_recreational_activity',\n",
    " 'have_health_insurance',\n",
    " 'num_dep_screener_0',\n",
    " 'weight_lbs_over_height_in_ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3515, 31)\n",
      "(879, 31)\n",
      "(3515,)\n",
      "(879,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>grouping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Depressed (No)</td>\n",
       "      <td>0.930757</td>\n",
       "      <td>0.782138</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.767918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Depressed (Yes)</td>\n",
       "      <td>0.375969</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.767918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.653363</td>\n",
       "      <td>0.737498</td>\n",
       "      <td>0.668719</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0.767918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.842395</td>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.792254</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0.767918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model         grouping  precision    recall  f1-score  \\\n",
       "0  Gaussian Naive Bayes   Depressed (No)   0.930757  0.782138  0.850000   \n",
       "1  Gaussian Naive Bayes  Depressed (Yes)   0.375969  0.692857  0.487437   \n",
       "2  Gaussian Naive Bayes        Macro Avg   0.653363  0.737498  0.668719   \n",
       "3  Gaussian Naive Bayes     Weighted Avg   0.842395  0.767918  0.792254   \n",
       "\n",
       "   support  accuracy  \n",
       "0    739.0  0.767918  \n",
       "1    140.0  0.767918  \n",
       "2    879.0  0.767918  \n",
       "3    879.0  0.767918  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_x_train, gnb_x_test, gnb_y_train, gnb_y_test = get_model_data(\n",
    "    original_df = cdc_survey_pmom_1plus_dep_screener,\n",
    "    columns = gnb_model_features\n",
    ")\n",
    "\n",
    "print(gnb_x_train.shape)\n",
    "print(gnb_x_test.shape)\n",
    "print(gnb_y_train.shape)\n",
    "print(gnb_y_test.shape)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(gnb_x_train, gnb_y_train)\n",
    "gnb_pred  = gnb.predict(gnb_x_test)\n",
    "gnb_score = get_performance_df(gnb_y_test, gnb_pred,'Gaussian Naive Bayes')  \n",
    "gnb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_param_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "#gnb_param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3101297...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3101297...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3101297...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_grid_search = GridSearchCV(\n",
    "    GaussianNB(),\n",
    "    param_grid=gnb_param_grid\n",
    ")\n",
    "gnb_grid_search.fit(gnb_x_train, gnb_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=1.0)\n"
     ]
    }
   ],
   "source": [
    "print(gnb_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>grouping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Depressed (No)</td>\n",
       "      <td>0.849537</td>\n",
       "      <td>0.993234</td>\n",
       "      <td>0.915783</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.846416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Depressed (Yes)</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.846416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.758102</td>\n",
       "      <td>0.532331</td>\n",
       "      <td>0.522408</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0.846416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.820411</td>\n",
       "      <td>0.846416</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0.846416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model         grouping  precision    recall  f1-score  \\\n",
       "0  Gaussian Naive Bayes   Depressed (No)   0.849537  0.993234  0.915783   \n",
       "1  Gaussian Naive Bayes  Depressed (Yes)   0.666667  0.071429  0.129032   \n",
       "2  Gaussian Naive Bayes        Macro Avg   0.758102  0.532331  0.522408   \n",
       "3  Gaussian Naive Bayes     Weighted Avg   0.820411  0.846416  0.790476   \n",
       "\n",
       "   support  accuracy  \n",
       "0    739.0  0.846416  \n",
       "1    140.0  0.846416  \n",
       "2    879.0  0.846416  \n",
       "3    879.0  0.846416  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_hyper = GaussianNB(var_smoothing=1.0)\n",
    "gnb_hyper.fit(gnb_x_train, gnb_y_train)\n",
    "gnb_hyper_pred  = gnb_hyper.predict(gnb_x_test)\n",
    "gnb_hyper_score = get_performance_df(gnb_y_test, gnb_hyper_pred,'Gaussian Naive Bayes')  \n",
    "gnb_hyper_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GB Classifier (train & predict on cdc_survey_pmom_1plus_dep_screener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb_x_train: (4512, 31)\n",
      "gb_y_train: (4512,)\n",
      "gb_x_test: (1129, 31)\n",
      "gb_y_test: (1129,)\n",
      "gb_x_train_rus: (1100, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>grouping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>Depressed (No)</td>\n",
       "      <td>0.959079</td>\n",
       "      <td>0.747012</td>\n",
       "      <td>0.839866</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.746678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>Depressed (Yes)</td>\n",
       "      <td>0.268012</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>0.394068</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.746678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.613545</td>\n",
       "      <td>0.745506</td>\n",
       "      <td>0.616967</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>0.746678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.882566</td>\n",
       "      <td>0.746678</td>\n",
       "      <td>0.790508</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>0.746678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model         grouping  precision    recall  \\\n",
       "0  Gradient Boosting Classifier   Depressed (No)   0.959079  0.747012   \n",
       "1  Gradient Boosting Classifier  Depressed (Yes)   0.268012  0.744000   \n",
       "2  Gradient Boosting Classifier        Macro Avg   0.613545  0.745506   \n",
       "3  Gradient Boosting Classifier     Weighted Avg   0.882566  0.746678   \n",
       "\n",
       "   f1-score  support  accuracy  \n",
       "0  0.839866   1004.0  0.746678  \n",
       "1  0.394068    125.0  0.746678  \n",
       "2  0.616967   1129.0  0.746678  \n",
       "3  0.790508   1129.0  0.746678  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_x_train, gb_x_test, gb_y_train, gb_y_test = get_model_data(\n",
    "    original_df = cdc_survey_pmom_1plus_dep_screener,\n",
    "    columns = gnb_model_features\n",
    ")\n",
    "\n",
    "rus = RandomUnderSampler(\n",
    "    random_state=42, \n",
    "    sampling_strategy=1,\n",
    "    replacement=False\n",
    ")\n",
    "gb_x_train_rus, gb_y_train_rus = rus.fit_resample(gb_x_train,gb_y_train)\n",
    "\n",
    "print(f\"gb_x_train: {gb_x_train.shape}\")\n",
    "print(f\"gb_y_train: {gb_y_train.shape}\")\n",
    "print(f\"gb_x_test: {gb_x_test.shape}\")\n",
    "print(f\"gb_y_test: {gb_y_test.shape}\")\n",
    "print(f\"gb_x_train_rus: {gb_x_train_rus.shape}\")\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(gb_x_train_rus, gb_y_train_rus)\n",
    "#gb_opt9.fit(x_train, y_train)\n",
    "gb_y_pred  = gb.predict(gb_x_test)\n",
    "gb_score = get_performance_df(gb_y_test, gb_y_pred,'Gradient Boosting Classifier')  \n",
    "gb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF Classifier (train & predict on cdc_survey_pmom_0dep_screener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bin_lookup(\n",
    "        feature,\n",
    "        n_bins,\n",
    "        encode,\n",
    "        strategy,\n",
    "        df_to_use):\n",
    "        # make a new column with _bin suffix\n",
    "        new_column_name = feature + '_bin'\n",
    "\n",
    "        # get non-null values per column\n",
    "        feature_values = df_to_use[feature].dropna()\n",
    "\n",
    "        # reshape to be 1 column\n",
    "        feature_values = feature_values.to_numpy().reshape([feature_values.shape[0],1])\n",
    "\n",
    "        # create bins using estimator\n",
    "        est = KBinsDiscretizer(\n",
    "            n_bins=n_bins,\n",
    "            encode=encode, \n",
    "            strategy=strategy, \n",
    "            subsample=None\n",
    "        )\n",
    "        est.fit(feature_values)\n",
    "        feature_values_bin = pd.DataFrame(est.transform(feature_values))\n",
    "\n",
    "        # dataframe with binned values\n",
    "        feature_values_bin.columns = [new_column_name]\n",
    "\n",
    "        # get original\n",
    "        feature_values = pd.DataFrame(feature_values)\n",
    "        feature_values.columns = ['original']\n",
    "\n",
    "        # merge bin & non-binned values together to make a lookup\n",
    "        feature_values = feature_values.merge(feature_values_bin, left_index=True, right_index=True)\n",
    "        feature_value_bin_lookup = feature_values.groupby(['original',new_column_name]).count().reset_index()\n",
    "\n",
    "        return feature_value_bin_lookup, new_column_name\n",
    "    \n",
    "feature_value_bin_lookup, new_column_name = create_bin_lookup(\n",
    "    'count_days_seen_doctor_12mo',\n",
    "    n_bins=10,\n",
    "    encode='ordinal',\n",
    "    strategy='uniform',\n",
    "    df_to_use=cdc_survey_pmom_0dep_screener\n",
    ")  \n",
    "\n",
    "# prevent creating a column if already exists\n",
    "# happens if you run this block multiple times\n",
    "if new_column_name in cdc_survey_pmom_0dep_screener.columns:\n",
    "    cdc_survey_pmom_0dep_screener.drop(columns=new_column_name,inplace=True)\n",
    "\n",
    "# add bin column in a way that doesn't drop nulls\n",
    "cdc_survey_pmom_0dep_screener = cdc_survey_pmom_0dep_screener.merge(\n",
    "    feature_value_bin_lookup, \n",
    "    left_on='count_days_seen_doctor_12mo', \n",
    "    right_on='original', \n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "# drop column called \"original\" as was only used to join\n",
    "cdc_survey_pmom_0dep_screener.drop(columns=['original'], inplace=True)  \n",
    "\n",
    "\n",
    "rf_model_features = [\n",
    "    'count_days_seen_doctor_12mo_bin',\n",
    "    'times_with_12plus_alc',\n",
    "    'seen_mental_health_professional',\n",
    "    'count_lost_10plus_pounds',\n",
    "    'arthritis',\n",
    "    'horomones_not_bc',\n",
    "    'is_usa_born',\n",
    "    'times_with_8plus_alc',\n",
    "    'time_since_last_healthcare',\n",
    "    'work_schedule'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2677, 10)\n",
      "(670, 10)\n",
      "(2677,)\n",
      "(670,)\n",
      "(849, 10)\n",
      "(849,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>grouping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Depressed (No)</td>\n",
       "      <td>0.964615</td>\n",
       "      <td>0.979688</td>\n",
       "      <td>0.972093</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.946269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Depressed (Yes)</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.946269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.657308</td>\n",
       "      <td>0.606510</td>\n",
       "      <td>0.626047</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.946269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.937095</td>\n",
       "      <td>0.946269</td>\n",
       "      <td>0.941104</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.946269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model         grouping  precision    recall  f1-score  \\\n",
       "0  Random Forest Classifier   Depressed (No)   0.964615  0.979688  0.972093   \n",
       "1  Random Forest Classifier  Depressed (Yes)   0.350000  0.233333  0.280000   \n",
       "2  Random Forest Classifier        Macro Avg   0.657308  0.606510  0.626047   \n",
       "3  Random Forest Classifier     Weighted Avg   0.937095  0.946269  0.941104   \n",
       "\n",
       "   support  accuracy  \n",
       "0    640.0  0.946269  \n",
       "1     30.0  0.946269  \n",
       "2    670.0  0.946269  \n",
       "3    670.0  0.946269  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_x_train, rf_x_test, rf_y_train, rf_y_test = get_model_data(\n",
    "    original_df = cdc_survey_pmom_0dep_screener,\n",
    "    columns = rf_model_features\n",
    ")\n",
    "\n",
    "rus = RandomUnderSampler(\n",
    "    random_state=42, \n",
    "    sampling_strategy=0.12,\n",
    "    replacement=False\n",
    ")\n",
    "\n",
    "\n",
    "rf_x_train_rus, rf_y_train_rus = rus.fit_resample(rf_x_train,rf_y_train)\n",
    "\n",
    "print(rf_x_train.shape)\n",
    "print(rf_x_test.shape)\n",
    "print(rf_y_train.shape)\n",
    "print(rf_y_test.shape)\n",
    "print(rf_x_train_rus.shape)\n",
    "print(rf_y_train_rus.shape)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(rf_x_train_rus, rf_y_train_rus)\n",
    "rf_pred = rf.predict(rf_x_test)\n",
    "rf_score = get_performance_df(rf_y_test, rf_pred,'Random Forest Classifier')\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       " 'max_features': ['auto', 'sqrt', 'log2', None],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = list(range(10,110, 10))\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = list(range(10,120, 10))\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "rf_param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    param_grid=rf_param_grid\n",
    ")\n",
    "rf_grid_search.fit(rf_x_train_rus, rf_y_train_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=3, max_leaf_nodes=9, n_estimators=25)\n"
     ]
    }
   ],
   "source": [
    "print(rf_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_x_train_rus.shape)\n",
    "\n",
    "rf_hyper = RandomForestClassifier(\n",
    "    n_estimators=,\n",
    "    max_features=,\n",
    "    max_depth=,\n",
    "    min_samples_split=,\n",
    "    min_samples_leaf=,\n",
    "    bootstrap=,\n",
    "    random_state=42\n",
    ")\n",
    "rf_hyper.fit(rf_x_train_rus, rf_y_train_rus)\n",
    "rf_hyper_pred = rf_hyper.predict(rf_x_test)\n",
    "rf_hyper_score = get_performance_df(rf_y_test, rf_hyper_pred,'Random Forest Classifier')\n",
    "rf_hyper_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc \n",
    "\n",
    "## GBC Classifier (train and predict on cdc_survey_pmom_0dep_screener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model_features = [\n",
    "    'times_with_12plus_alc',\n",
    "    'seen_mental_health_professional',\n",
    "    'count_days_seen_doctor_12mo',\n",
    "    'count_lost_10plus_pounds',\n",
    "    'arthritis',\n",
    "    'horomones_not_bc',\n",
    "    'is_usa_born',\n",
    "    'times_with_8plus_alc',\n",
    "    'time_since_last_healthcare',\n",
    "    'work_schedule',\n",
    "    'age_in_years'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2677, 11)\n",
      "(670, 11)\n",
      "(2677,)\n",
      "(670,)\n",
      "(849, 11)\n",
      "(849,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>grouping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>Depressed (No)</td>\n",
       "      <td>0.967239</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.967994</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.938806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>Depressed (Yes)</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.938806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.638792</td>\n",
       "      <td>0.634375</td>\n",
       "      <td>0.636539</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.938806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.937826</td>\n",
       "      <td>0.938806</td>\n",
       "      <td>0.938311</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.938806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model         grouping  precision    recall  \\\n",
       "0  Gradient Boosting Classifier   Depressed (No)   0.967239  0.968750   \n",
       "1  Gradient Boosting Classifier  Depressed (Yes)   0.310345  0.300000   \n",
       "2  Gradient Boosting Classifier        Macro Avg   0.638792  0.634375   \n",
       "3  Gradient Boosting Classifier     Weighted Avg   0.937826  0.938806   \n",
       "\n",
       "   f1-score  support  accuracy  \n",
       "0  0.967994    640.0  0.938806  \n",
       "1  0.305085     30.0  0.938806  \n",
       "2  0.636539    670.0  0.938806  \n",
       "3  0.938311    670.0  0.938806  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_x_train, gb_x_test, gb_y_train, gb_y_test = get_model_data(\n",
    "    original_df = cdc_survey_pmom_0dep_screener,\n",
    "    columns = gb_model_features\n",
    ")\n",
    "\n",
    "rus = RandomUnderSampler(\n",
    "    random_state=42, \n",
    "    sampling_strategy=0.12,\n",
    "    replacement=False\n",
    ")\n",
    "\n",
    "gb_x_train_rus, gb_y_train_rus = rus.fit_resample(gb_x_train,gb_y_train)\n",
    "\n",
    "print(gb_x_train.shape)\n",
    "print(gb_x_test.shape)\n",
    "print(gb_y_train.shape)\n",
    "print(gb_y_test.shape)\n",
    "print(gb_x_train_rus.shape)\n",
    "print(gb_y_train_rus.shape)\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(gb_x_train_rus, gb_y_train_rus)\n",
    "gb_pred = gb.predict(gb_x_test)\n",
    "gb_score = get_performance_df(gb_y_test, gb_pred,'Gradient Boosting Classifier')\n",
    "gb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': ['log_loss', 'exponential', 'deviance'],\n",
       " 'learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2, 0.3],\n",
       " 'max_depth': [2, 3, 5, 8],\n",
       " 'max_features': ['log2', 'sqrt'],\n",
       " 'subsample': [0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
       " 'n_estimators': [10, 30, 70, 100, 200]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/hatone/gradientboostingclassifier-with-gridsearchcv/script\n",
    "\n",
    "gb_param_grid = {\n",
    "    \"loss\":[\"log_loss\",\"exponential\",\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2, 0.3],\n",
    "    #\"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    #\"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[2,3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    #\"criterion\": [\"friedman_mse\", \"mae\",\"squared_error\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10, 30, 70, 100, 200]\n",
    "}\n",
    "gb_param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.025, 0.05, 0.075, 0.1, 0.15,\n",
       "                                           0.2, 0.3],\n",
       "                         &#x27;loss&#x27;: [&#x27;log_loss&#x27;, &#x27;exponential&#x27;, &#x27;deviance&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [2, 3, 5, 8],\n",
       "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 30, 70, 100, 200],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.025, 0.05, 0.075, 0.1, 0.15,\n",
       "                                           0.2, 0.3],\n",
       "                         &#x27;loss&#x27;: [&#x27;log_loss&#x27;, &#x27;exponential&#x27;, &#x27;deviance&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [2, 3, 5, 8],\n",
       "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 30, 70, 100, 200],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15,\n",
       "                                           0.2, 0.3],\n",
       "                         'loss': ['log_loss', 'exponential', 'deviance'],\n",
       "                         'max_depth': [2, 3, 5, 8],\n",
       "                         'max_features': ['log2', 'sqrt'],\n",
       "                         'n_estimators': [10, 30, 70, 100, 200],\n",
       "                         'subsample': [0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid_search = GridSearchCV(\n",
    "    GradientBoostingClassifier(),\n",
    "    param_grid=gb_param_grid\n",
    ")\n",
    "gb_grid_search.fit(gb_x_train_rus, gb_y_train_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(learning_rate=0.05, loss='exponential', max_depth=2,\n",
      "                           max_features='log2', n_estimators=200,\n",
      "                           subsample=0.8)\n"
     ]
    }
   ],
   "source": [
    "print(gb_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(849, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>grouping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Classifier (Hyper)</td>\n",
       "      <td>Depressed (No)</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.968992</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.940299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting Classifier (Hyper)</td>\n",
       "      <td>Depressed (Yes)</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.940299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting Classifier (Hyper)</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.605769</td>\n",
       "      <td>0.571615</td>\n",
       "      <td>0.584496</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.940299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier (Hyper)</td>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.929679</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.934560</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.940299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  model         grouping  precision    recall  \\\n",
       "0  Gradient Boosting Classifier (Hyper)   Depressed (No)   0.961538  0.976562   \n",
       "1  Gradient Boosting Classifier (Hyper)  Depressed (Yes)   0.250000  0.166667   \n",
       "2  Gradient Boosting Classifier (Hyper)        Macro Avg   0.605769  0.571615   \n",
       "3  Gradient Boosting Classifier (Hyper)     Weighted Avg   0.929679  0.940299   \n",
       "\n",
       "   f1-score  support  accuracy  \n",
       "0  0.968992    640.0  0.940299  \n",
       "1  0.200000     30.0  0.940299  \n",
       "2  0.584496    670.0  0.940299  \n",
       "3  0.934560    670.0  0.940299  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gb_x_train_rus.shape)\n",
    "\n",
    "gb_hyper = GradientBoostingClassifier(\n",
    "    learning_rate=0.05,\n",
    "    loss='exponential',\n",
    "    max_depth=2,\n",
    "    max_features='log2',\n",
    "    n_estimators=200,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "gb_hyper.fit(gb_x_train_rus, gb_y_train_rus)\n",
    "gb_hyper_pred = gb_hyper.predict(gb_x_test)\n",
    "gb_hyper_score = get_performance_df(gb_y_test, gb_hyper_pred,'Gradient Boosting Classifier (Hyper)')\n",
    "gb_hyper_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
