{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add annotations describing usage of different modules\n",
    "\n",
    "from operator import mod\n",
    "from os import getcwd\n",
    "from os.path import exists, join\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from ydata_profiling import ProfileReport\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "# import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import pickle\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "import altair as alt\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set seaborn whitegrid theme\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from random import sample\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(pred_labels, y_test, algo_name, show_full_report=False):\n",
    "    eval_on = 'macro avg' \n",
    "    # eval_on = 'depressed' #not_depressed\n",
    "    target_names = ['not_depressed', 'depressed',]\n",
    "    \n",
    "    df_cls_rpt = pd.DataFrame(\n",
    "        classification_report(\n",
    "            y_test, \n",
    "            pred_labels, \n",
    "            target_names=target_names, \n",
    "            output_dict=True\n",
    "        )\n",
    "    ).rename_axis('metric')\\\n",
    "    .reset_index()\n",
    "\n",
    "    \n",
    "    if show_full_report == True:\n",
    "        display(df_cls_rpt)\n",
    "    accuracy = df_cls_rpt[['accuracy']].iloc[0, 0]\n",
    "    df_cls_rpt = df_cls_rpt[['metric', eval_on]].T\n",
    "    df_cls_rpt.columns = df_cls_rpt.iloc[0,:]\n",
    "    df_cls_rpt = df_cls_rpt.iloc[1:,:]\n",
    "    df_cls_rpt['accuracy'] = accuracy\n",
    "\n",
    "    df_cls_rpt['algo'] = algo_name\n",
    "\n",
    "    first_column = df_cls_rpt.pop('algo')\n",
    "    df_cls_rpt.insert(0, 'algo', first_column)\n",
    "\n",
    "    # display(df_cls_rpt)\n",
    "    return df_cls_rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_grid_search_pred(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test,\n",
    "    y_test,\n",
    "    algo,\n",
    "    algo_name,\n",
    "    params,\n",
    "    cv,\n",
    "    verbose,\n",
    "    imputer,\n",
    "    scaler,\n",
    "    score_on):\n",
    "\n",
    "    if score_on == 'f1-score':\n",
    "        score_on = 'f1_macro'\n",
    "    if algo_name == 'Multinomial Naive Bayes':\n",
    "        X_train[X_train < 0] = 0\n",
    "        X_test[X_test < 0] = 0\n",
    "        X_train = np.nan_to_num(X_train)\n",
    "        X_test = np.nan_to_num(X_test)\n",
    "\n",
    "    pipeline_list = [imputer, scaler, algo]\n",
    "    # drop imputer or scaler if none\n",
    "    pipeline_list = [step for step in pipeline_list if step is not None]\n",
    "\n",
    "    processing_pipeline = make_pipeline(imputer, scaler, algo)\n",
    "    processing_pipeline = make_pipeline()\n",
    "    i = 1\n",
    "    for step in pipeline_list:\n",
    "        processing_pipeline.steps.append([(type(step).__name__).lower(), step])\n",
    "        i += 1\n",
    "    grid = GridSearchCV(\n",
    "        processing_pipeline, \n",
    "        param_grid=params, \n",
    "        n_jobs=-1, \n",
    "        cv=cv, \n",
    "        verbose=verbose, \n",
    "        scoring=score_on)\n",
    "    if algo_name == 'gnb':\n",
    "        X_test = PowerTransformer().fit_transform(X_test)\n",
    "\n",
    "        # grid.fit(X_test, y_test)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    pred_labels = [x.round() for x in grid.best_estimator_.predict(X_test)]\n",
    "    pred_labels = [x.round() for x in pred_labels]\n",
    "\n",
    "    df_algo_cls_rpt = get_classification_report(pred_labels, y_test, algo_name)\n",
    "    df_algo_cls_rpt['train_r2'] = grid.best_estimator_.score(X_train, y_train)\n",
    "    df_algo_cls_rpt['test_r2'] = grid.best_estimator_.score(X_test, y_test)\n",
    "    df_algo_cls_rpt['best_params'] = str(grid.best_params_)\n",
    "    tn, fp, fn, tp = confusion_matrix(pred_labels, y_test).ravel()\n",
    "    df_algo_cls_rpt['tp'] = tp\n",
    "    df_algo_cls_rpt['fn'] = fn\n",
    "    df_algo_cls_rpt['fp'] = fp\n",
    "    df_algo_cls_rpt['tn'] = tn\n",
    "\n",
    "    \n",
    "    return df_algo_cls_rpt, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_baseline_pred(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test,\n",
    "    y_test,\n",
    "    show_full_report,\n",
    "    algo,\n",
    "    algo_name,\n",
    "    imputer,\n",
    "    scaler):\n",
    "    \n",
    "    if algo_name == 'Multinomial Naive Bayes':\n",
    "        X_train[X_train < 0] = 0\n",
    "        X_test[X_test < 0] = 0\n",
    "        X_train = np.nan_to_num(X_train)\n",
    "        X_test = np.nan_to_num(X_test)\n",
    "\n",
    "    pipeline_list = [imputer, scaler, algo]\n",
    "    # drop imputer or scaler if none\n",
    "    pipeline_list = [step for step in pipeline_list if step is not None]\n",
    "    \n",
    "    try:\n",
    "        processing_pipeline = make_pipeline()\n",
    "        i = 1\n",
    "        for step in pipeline_list:\n",
    "            processing_pipeline.steps.append([(type(step).__name__).lower(), step])\n",
    "            i += 1\n",
    "\n",
    "        processing_pipeline.fit(X_train, y_train)\n",
    "        pred_labels  = processing_pipeline.predict(X_test)\n",
    "        pred_labels = [x.round() for x in pred_labels]\n",
    "\n",
    "        df_algo_cls_rpt = get_classification_report(pred_labels, y_test, algo_name, show_full_report)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, pred_labels).ravel()\n",
    "        df_algo_cls_rpt['tp'] = tp\n",
    "        df_algo_cls_rpt['fn'] = fn\n",
    "        df_algo_cls_rpt['fp'] = fp\n",
    "        df_algo_cls_rpt['tn'] = tn\n",
    "        \n",
    "        return df_algo_cls_rpt, pred_labels\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        raise Exception (f'{algo_name} might not work with NaN')\n",
    "        \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def baseline_models(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test, \n",
    "    y_test,\n",
    "    algo_attempt_list,\n",
    "    do_smote=False,\n",
    "    show_confusion_matrix=False,\n",
    "    show_full_report=False,\n",
    "    grid_search=False,\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    imputer=SimpleImputer(),\n",
    "    scaler=RobustScaler(),\n",
    "    bin_vars=False,\n",
    "    score_on='recall'):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # do_smote\n",
    "    if do_smote == True:\n",
    "        # have to impute first because smote won't take nulls\n",
    "        my_imputer = SimpleImputer()\n",
    "        X_train = my_imputer.fit_transform(X_train)\n",
    "        X_test = my_imputer.fit_transform(X_test)\n",
    "\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # if bin_vars == True:\n",
    "    #     est = KBinsDiscretizer(\n",
    "    #         n_bins=3,\n",
    "    #         encode='ordinal', \n",
    "    #         strategy='uniform', \n",
    "    #         subsample=None\n",
    "    #     )\n",
    "    #     my_imputer = SimpleImputer()\n",
    "    #     X_train = my_imputer.fit_transform(X_train)\n",
    "    #     X_test = my_imputer.fit_transform(X_test)\n",
    "        \n",
    "    #     est.fit(X_train)\n",
    "    #     X_train = est.transform(X_train)\n",
    "\n",
    "    #     est.fit(X_test)\n",
    "    #     X_test = est.transform(X_test)\n",
    "\n",
    "    df_cls_rpt = pd.DataFrame()\n",
    "    conf_mtrx_dict = {}\n",
    "\n",
    "    if algo_attempt_list == 'all':\n",
    "        algo_attempt_list = ['knn', 'lm', 'bnb', 'gnb', 'dt', 'rf', 'gb', 'xgb']\n",
    "    \n",
    "    for a in algo_attempt_list:\n",
    "        # SVR\n",
    "        if a == 'svr':\n",
    "            algo_name = 'SVR'\n",
    "            params = {\n",
    "                \"simpleimputer__strategy\": [\"mean\", \"median\"],\n",
    "                \"robustscaler__quantile_range\": [(25.0, 75.0), (30.0, 70.0)],\n",
    "                \"svr__C\": [0.1, 1.0],\n",
    "                \"svr__gamma\": [\"auto\", 0.1],\n",
    "            }\n",
    "            algo = SVR()\n",
    "        elif a == 'knn':\n",
    "            algo_name = 'KNN'\n",
    "            params = {\n",
    "                'kneighborsclassifier__n_neighbors': list(range(1, 15))\n",
    "            }\n",
    "            print(params)\n",
    "            algo = KNeighborsClassifier()\n",
    "        elif a == 'lm':\n",
    "            algo_name = 'Logistic Regression'\n",
    "            params = {\n",
    "                'logisticregression__penalty': ['l1','l2'], \n",
    "                'logisticregression__C': [0.001,0.01,0.1,1,10,100,1000]\n",
    "            }\n",
    "            algo = LogisticRegression(max_iter=1000, penalty='l2', C=10)\n",
    "        elif a == 'bnb':\n",
    "            algo_name = 'Bernoulli Naive Bayes'\n",
    "            params = {\n",
    "                'bernoullinb__alpha': np.logspace(0,-9, num=100),\n",
    "                'bernoullinb__binarize': [0.0, 1.0, 2.0],\n",
    "                'bernoullinb__fit_prior': [True, False]\n",
    "            }\n",
    "            algo = BernoulliNB()\n",
    "        elif a == 'gnb':\n",
    "            algo_name = 'Gaussian Naive Bayes'\n",
    "            params = {\n",
    "                'gaussiannb__var_smoothing': np.logspace(0,-9, num=100)\n",
    "            }\n",
    "            algo = GaussianNB()\n",
    "        elif a == 'mnb':\n",
    "            algo_name = 'Multinomial Naive Bayes'\n",
    "            params = {\n",
    "                'multinomialnb__alpha': np.logspace(0,-9, num=100),\n",
    "            }\n",
    "            algo = MultinomialNB()\n",
    "            \n",
    "        elif a == 'dt':\n",
    "            algo_name = 'Decision Tree'\n",
    "            params = {\n",
    "                'decisiontreeclassifier__criterion':['gini', 'entropy', 'logloss'],\n",
    "                'decisiontreeclassifier__max_depth': np.arange(1, 15)\n",
    "            }\n",
    "            algo = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        elif a == 'rf':\n",
    "            algo_name = 'Random Forest'\n",
    "            params = {\n",
    "                'randomforestclassifier__criterion': ['gini', 'entropy', 'logloss'],\n",
    "                \"randomforestclassifier__n_estimators\": [10, 20, 40, 80, 100, 125, 150],\n",
    "                \"randomforestclassifier__max_features\": [\"sqrt\", \"log2\", None],\n",
    "                \"randomforestclassifier__min_samples_split\": [1, 2, 4, 8],\n",
    "                \"randomforestclassifier__bootstrap\": [True, False],\n",
    "            }\n",
    "            algo = RandomForestClassifier(random_state=42)\n",
    "        elif a == 'gb':\n",
    "            algo_name = 'Gradient Boosting Classifier'\n",
    "            params = {\n",
    "                \"gradientboostingclassifier__loss\":[\"log_loss\", \"exponential\"],\n",
    "                \"gradientboostingclassifier__learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "                # \"gradientboostingclassifier__min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "                # \"gradientboostingclassifier__min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "                \"gradientboostingclassifier__max_depth\":[3,5,8],\n",
    "                \"gradientboostingclassifier__max_features\":[\"log2\", \"sqrt\"],\n",
    "                \"gradientboostingclassifier__criterion\": [\"friedman_mse\", \"mae\"],\n",
    "                # \"gradientboostingclassifier__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "                \"gradientboostingclassifier__n_estimators\":[10, 25, 50, 100, 125, 150]\n",
    "            }\n",
    "            algo = GradientBoostingClassifier()\n",
    "        elif a == 'xgb':\n",
    "            algo_name = 'XGBoost'\n",
    "            params = {\n",
    "                'xgbclassifier__max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "                'xgbclassifier__learning_rate': [0.001, 0.01, 0.1, 0.20, 0.25, 0.30],\n",
    "                \"xgbclassifier__gamma\":[0, 0.25, 0.5, 0.75,1],\n",
    "                'xgbclassifier__n_estimators': [100, 500, 1000],\n",
    "            }\n",
    "            algo = xgb.XGBClassifier()\n",
    "        elif a == 'mlp':\n",
    "            # X = [[0., 0.], [1., 1.]]\n",
    "            # y = [0, 1]\n",
    "            algo_name = 'MLP'\n",
    "            algo = MLPClassifier(\n",
    "                max_iter=1000\n",
    "                # solver='lbfgs', \n",
    "                # alpha=1e-5,\n",
    "                # hidden_layer_sizes=(5, 2),\n",
    "                # random_state=42,\n",
    "            )\n",
    "            params = {\n",
    "                'mlpclassifier__solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "                'mlpclassifier__activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                'mlpclassifier__early_stopping' : [True, False]\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            raise Exception(f'{a} is not a supported algorithm')\n",
    "            # print(f'{a} is not a supported algorithm')\n",
    "\n",
    "        if grid_search == True and params is not None:\n",
    "            df_algo_cls_rpt, pred_labels = algo_grid_search_pred(\n",
    "                X_train, \n",
    "                y_train, \n",
    "                X_test,\n",
    "                y_test,\n",
    "                algo=algo,\n",
    "                algo_name=algo_name,\n",
    "                params=params,\n",
    "                imputer=imputer,\n",
    "                scaler=scaler,\n",
    "                cv=cv,\n",
    "                verbose=verbose,\n",
    "                score_on=score_on\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            if grid_search == True and params is None:\n",
    "                # print(f'Params not defined for {algo_name} GridSearch. Fitting baseline model.')\n",
    "                pass\n",
    "            df_algo_cls_rpt, pred_labels = algo_baseline_pred(\n",
    "                X_train, \n",
    "                y_train, \n",
    "                X_test,\n",
    "                y_test,\n",
    "                show_full_report,\n",
    "                algo=algo,\n",
    "                algo_name=algo_name,\n",
    "                imputer=imputer,\n",
    "                scaler=scaler,\n",
    "            )\n",
    "\n",
    "        df_cls_rpt = pd.concat([\n",
    "                df_algo_cls_rpt, \n",
    "                df_cls_rpt], \n",
    "                ignore_index=True\n",
    "        )\n",
    "        conf_mtrx_dict[algo_name] = pred_labels\n",
    "    \n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        for k,v in conf_mtrx_dict.items():\n",
    "            print(f'{k} Confusion Matrix')\n",
    "            plot_confusion_matrix(y_test, v)\n",
    "\n",
    "    df_cls_rpt.sort_values(by=['f1-score'], ascending=False, inplace=True)\n",
    "    df_cls_rpt = df_cls_rpt.reset_index(drop=True)\n",
    "    return df_cls_rpt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35706, 863)\n",
      "(7741, 863)\n"
     ]
    }
   ],
   "source": [
    "cdc_survey = pd.read_csv('../../data/cdc_nhanes_survey_responses_clean.csv')\n",
    "print(cdc_survey.shape)\n",
    "\n",
    "# filter to pregnant moms\n",
    "cdc_survey_pmom = cdc_survey[cdc_survey['has_been_pregnant'] == 1]\n",
    "print(cdc_survey_pmom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depression screener\n",
    "dep_screener_cols = [\n",
    "    'little_interest_in_doing_things',\n",
    "    'feeling_down_depressed_hopeless',\n",
    "    'trouble_falling_or_staying_asleep',\n",
    "    'feeling_tired_or_having_little_energy',\n",
    "    'poor_appetitie_or_overeating',\n",
    "    'feeling_bad_about_yourself',\n",
    "    'trouble_concentrating',\n",
    "    'moving_or_speaking_to_slowly_or_fast',\n",
    "    'thoughts_you_would_be_better_off_dead',\n",
    "    'difficult_doing_daytoday_tasks'\n",
    "]\n",
    "\n",
    "# Alcohol & smoking\n",
    "alcohol_n_smoking_cols = [\n",
    "    'has_smoked_tabacco_last_5days',\n",
    "    'alcoholic_drinks_past_12mo', \n",
    "    'drank_alc',\n",
    "    'alc_drinking_freq',\n",
    "    'alc_per_day',\n",
    "    'times_with_4or5_alc',\n",
    "    'times_with_8plus_alc',\n",
    "    'times_with_12plus_alc',\n",
    "    '4plus_alc_daily',\n",
    "    'days_4plus_drinks_occasion',\n",
    "    'smoked_100_cigs',\n",
    "    'currently_smoke'\n",
    "]\n",
    "\n",
    "#Medical Conditions \n",
    "med_condition_cols = [\n",
    "    'chest_discomfort',\n",
    "    'asthma',\n",
    "    'anemia_treatment',\n",
    "    'blood_transfusion',\n",
    "    'arthritis',\n",
    "    'heart_failure',\n",
    "    'coronary_heart_disease',\n",
    "    'angina_pectoris',\n",
    "    'heart_attack',\n",
    "    'stroke',\n",
    "    'thyroid_issues',\n",
    "    'respiratory_issues',\n",
    "    'abdominal_pain',\n",
    "    'gallstones',\n",
    "    'gallbladder_surgery',\n",
    "    'cancer',\n",
    "    'dr_recommend_lose_weight',\n",
    "    'dr_recommend_exercise',\n",
    "    'dr_recommend_reduce_salt',\n",
    "    'dr_recommend_reduce_fat',\n",
    "    'currently_losing_weight',\n",
    "    'currently_increase_exercise',\n",
    "    'currently_reducing_salt',\n",
    "    'currently_reducing_fat',\n",
    "    'metal_objects',\n",
    "    'has_diabetes',    \n",
    "    #Blood Pressure & Cholesterol \n",
    "    'high_bp',\n",
    "    'age_hypertension',\n",
    "    'hypertension_prescription',\n",
    "    'high_bp_prescription',\n",
    "    'high_cholesterol',\n",
    "    'cholesterol_prescription',\n",
    "    # general health\n",
    "    'has_overweight_diagnosis',   \n",
    "    'height_in',\n",
    "    'weight_lbs', \n",
    "    #'weight_lbs_over_height_in_ratio',\n",
    "    'general_health_condition',      \n",
    "]\n",
    "\n",
    "# diet, nutrition, & exercise \n",
    "lifestyle_cols = [\n",
    "    # exercise/weight loss\n",
    "    'vigorous_work',\n",
    "    'walk_or_bicycle',\n",
    "    'vigorous_recreation',\n",
    "    'moderate_recreation',    \n",
    "    'count_days_moderate_recreational_activity',   \n",
    "    'count_minutes_moderate_recreational_activity',\n",
    "    'count_minutes_moderate_sedentary_activity',    \n",
    "    'count_lost_10plus_pounds',\n",
    "    'has_tried_to_lose_weight_12mo', \n",
    "    'attempt_weight_loss_1yr',           \n",
    "    # diet\n",
    "    'how_healthy_is_your_diet',    \n",
    "    'milk_consumption_freq',\n",
    "    'govmnt_meal_delivery',\n",
    "    'nonhomemade_meals',\n",
    "    'fastfood_meals',\n",
    "    'readytoeat_meals',\n",
    "    'frozen_pizza'   \n",
    "]\n",
    "\n",
    "# Reproductive Health \n",
    "reproductive_health_cols = [\n",
    "    'regular_periods',\n",
    "    'age_last_period',\n",
    "    'try_pregnancy_1yr',\n",
    "    'see_dr_fertility',\n",
    "    'pelvic_infection',\n",
    "    'pregnant_now',\n",
    "    'pregnancy_count',\n",
    "    'diabetes_pregnancy',\n",
    "    'delivery_count',\n",
    "    'live_birth_count',\n",
    "    'age_at_first_birth',\n",
    "    'age_at_last_birth',\n",
    "    'months_since_birth',\n",
    "    'horomones_not_bc'\n",
    "]\n",
    "\n",
    "# hospital usage & access to care\n",
    "hospital_utilization_n_access_cols = [\n",
    "    'general_health',\n",
    "    'regular_healthcare_place',\n",
    "    'time_since_last_healthcare',\n",
    "    'overnight_in_hospital',\n",
    "    'seen_mental_health_professional',\n",
    "    'count_days_seen_doctor_12mo',\n",
    "    'duration_last_healthcare_visit',   \n",
    "]\n",
    "\n",
    "# socioeconomic status\n",
    "socioeconomic_cols = [\n",
    "    #Food Security\n",
    "    'emergency_food_received',\n",
    "    'food_stamps_used',      \n",
    "    #Health Insurance\n",
    "    'have_health_insurance',\n",
    "    'have_private_insurance',\n",
    "    'plan_cover_prescriptions',   \n",
    "    #Income\n",
    "    'family_poverty_level',\n",
    "    'family_poverty_level_category',\n",
    "    #Occupation\n",
    "    'hours_worked',\n",
    "    'over_35_hrs_worked',\n",
    "    'work_schedule'    \n",
    "]\n",
    "\n",
    "demographic_cols = [\n",
    "    'food_security_level_household',   \n",
    "    'food_security_level_adult',    \n",
    "    'monthly_poverty_index_category',\n",
    "    'monthly_poverty_index',\n",
    "    'count_hours_worked_last_week',\n",
    "    'age_in_years',   \n",
    "    'education_level',\n",
    "    'is_usa_born',    \n",
    "    'has_health_insurance',\n",
    "    'has_health_insurance_gap'   \n",
    "]\n",
    "\n",
    "# combine all candidate features\n",
    "candidate_features = dep_screener_cols + \\\n",
    "    alcohol_n_smoking_cols + \\\n",
    "    med_condition_cols + \\\n",
    "    hospital_utilization_n_access_cols + \\\n",
    "    lifestyle_cols + \\\n",
    "    socioeconomic_cols + \\\n",
    "    reproductive_health_cols + \\\n",
    "    demographic_cols\n",
    "\n",
    "\n",
    "len(candidate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(original_df, \n",
    "                   columns, \n",
    "                   test_size_to_use=0.2,\n",
    "                   drop_null_rows=False,\n",
    "                   null_imputer_strategy='median', # mean, median, most_frequent\n",
    "                   use_value_scaler=True,\n",
    "                   use_smote=False):\n",
    "    \"\"\"\n",
    "    Function to build feature & indicator matrices for both train & test.\n",
    "    \"\"\"\n",
    "    \n",
    "    # add target column (MDD)\n",
    "    cols_to_use = columns.copy()\n",
    "    cols_to_use.insert(0, 'MDD')\n",
    "    \n",
    "    df_to_use = original_df[cols_to_use]\n",
    "    \n",
    "    if drop_null_rows:\n",
    "        df_to_use.dropna(inplace=True)\n",
    "    \n",
    "    # Create test & train data\n",
    "    x = df_to_use.iloc[:,1:].values\n",
    "    y = df_to_use['MDD'].values\n",
    "    \n",
    "    if not drop_null_rows:\n",
    "        # SimpleImputer() = fill in missing values\n",
    "        # note imputer may drop columns if no values exist for it\n",
    "        imputer = SimpleImputer(strategy=null_imputer_strategy)  \n",
    "        x = imputer.fit_transform(x)\n",
    "\n",
    "    # RobustScaler() = scale features to remove outliers\n",
    "    if use_value_scaler:\n",
    "        trans = RobustScaler()\n",
    "        x = trans.fit_transform(x)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, \n",
    "        y, \n",
    "        test_size=test_size_to_use, \n",
    "        random_state=42\n",
    "    ) \n",
    "    \n",
    "    # Technique to de-risk from positive class imbalance\n",
    "    if use_smote:\n",
    "        sm = SMOTE(random_state=42)\n",
    "        x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_df(label_actual, label_pred, model_name):\n",
    "    \"\"\"\n",
    "    Function to calculate performance metrics for model.\n",
    "    Includes precision, recal, F1, & support.\n",
    "    \"\"\"\n",
    "    # create classification report\n",
    "    result_table = classification_report(label_actual, label_pred, output_dict=True)\n",
    "    result_table = pd.DataFrame.from_dict(result_table)\n",
    "\n",
    "    # store for later\n",
    "    accuracies = result_table['accuracy'][0]\n",
    "    \n",
    "    column_key = {\n",
    "        '0':'depressed_no',\n",
    "         '1':'depressed_yes',\n",
    "         'accuracy':'accuracy',\n",
    "         'macro avg':'macro_avg',\n",
    "         'weighted avg':'weighted_avg'\n",
    "    }\n",
    "\n",
    "    # rename grouping\n",
    "    result_table.columns = [column_key.get(key) for key in result_table.columns]\n",
    "\n",
    "    # create dataframe with 1 row per grouping\n",
    "    result_table.drop(labels = 'accuracy', axis = 1, inplace=True)\n",
    "    result_table = result_table.transpose()\n",
    "    result_table['accuracy'] = [accuracies for i in range(result_table.shape[0])]\n",
    "    result_table = result_table.reset_index()\n",
    "    result_table.rename(columns = {'index':'grouping'},inplace=True)\n",
    "    result_table['model'] = model_name\n",
    "    result_table = result_table[['model','grouping','precision','recall','f1-score','support','accuracy']]\n",
    "    return result_table\n",
    "\n",
    "\n",
    "def generate_models(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    x_test, \n",
    "    y_test):\n",
    "    \"\"\"\n",
    "    Function that trains and makes predictions using 5 of the classifiers went over during the class.\n",
    "    Meant as a helper function for easier testing of different modeling pipelines.\n",
    "    \"\"\"\n",
    "\n",
    "    # K-Nearest Neighbors\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(x_train, y_train)\n",
    "    # test\n",
    "    pred_labels_knn  = knn.predict(x_test)\n",
    "    score_knn = get_performance_df(y_test, pred_labels_knn,'Knn')\n",
    "    # train\n",
    "    pred_labels_knn_train  = knn.predict(x_train)\n",
    "    score_knn_train = get_performance_df(y_train, pred_labels_knn_train,'Knn')\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lm = LogisticRegression()\n",
    "    lm.fit(x_train, y_train)\n",
    "    # test \n",
    "    pred_labels_lr  = lm.predict(x_test)\n",
    "    score_lr = get_performance_df(y_test, pred_labels_lr,'Logistic Regression')\n",
    "    # train \n",
    "    pred_labels_lr_train  = lm.predict(x_train)\n",
    "    score_lr_train = get_performance_df(y_train, pred_labels_lr_train,'Logistic Regression')    \n",
    "        \n",
    "    # Bernoulii Naive Bayes\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(x_train, y_train)\n",
    "    # test \n",
    "    pred_labels_bnb  = bnb.predict(x_test)\n",
    "    score_bnb = get_performance_df(y_test, pred_labels_bnb,'Bernoulli Naive Bayes')    \n",
    "    # train \n",
    "    pred_labels_bnb_train  = bnb.predict(x_train)\n",
    "    score_bnb_train = get_performance_df(y_train, pred_labels_bnb_train,'Bernoulli Naive Bayes')       \n",
    "        \n",
    "    # Gaussian Naive Bayes\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    # test \n",
    "    pred_labels_gnb  = gnb.predict(x_test)\n",
    "    score_gnb = get_performance_df(y_test, pred_labels_gnb,'Gaussian Naive Bayes')  \n",
    "    # train \n",
    "    pred_labels_gnb_train  = gnb.predict(x_train)\n",
    "    score_gnb_train = get_performance_df(y_train, pred_labels_gnb_train,'Gaussian Naive Bayes')         \n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(random_state=0)\n",
    "    rf.fit(x_train, y_train)\n",
    "    # test     \n",
    "    pred_labels_rf  = rf.predict(x_test)\n",
    "    score_rf = get_performance_df(y_test, pred_labels_rf,'Random Forest')   \n",
    "    # train \n",
    "    pred_labels_rf_train  = rf.predict(x_train)\n",
    "    score_rf_train = get_performance_df(y_train, pred_labels_rf_train,'Random Forest')         \n",
    "    \n",
    "    #Decision Tree\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(x_train, y_train)\n",
    "    # test\n",
    "    pred_labels_dt = dt.predict(x_test)\n",
    "    score_dt = get_performance_df(y_test, pred_labels_dt,'Decision Tree')\n",
    "    # train \n",
    "    pred_labels_dt_train  = dt.predict(x_train)\n",
    "    score_dt_train = get_performance_df(y_train, pred_labels_dt_train,'Decision Tree')          \n",
    "\n",
    "    #Gradient Boosting Classifier\n",
    "    gb = GradientBoostingClassifier()\n",
    "    gb.fit(x_train, y_train)\n",
    "    # test \n",
    "    pred_labels_gb = gb.predict(x_test)\n",
    "    score_gb = get_performance_df(y_test, pred_labels_gb,'Gradient Boosting Classifier')\n",
    "    # train \n",
    "    pred_labels_gb_train  = gb.predict(x_train)\n",
    "    score_gb_train = get_performance_df(y_train, pred_labels_gb_train,'Gradient Boosting Classifier')     \n",
    "    \n",
    "    # make dataframe with scores (on test data)\n",
    "    scores = pd.concat(\n",
    "        [score_knn, \n",
    "         score_lr, \n",
    "         score_bnb, \n",
    "         score_gnb, \n",
    "         score_rf, \n",
    "         score_dt, \n",
    "         score_gb]\n",
    "    )\n",
    "    scores = scores.sort_values(by = 'recall', ascending=False)\n",
    "    \n",
    "    # make dataframe with scores (on train data)\n",
    "    scores_train = pd.concat(\n",
    "        [score_knn_train, \n",
    "         score_lr_train, \n",
    "         score_bnb_train, \n",
    "         score_gnb_train, \n",
    "         score_rf_train, \n",
    "         score_dt_train, \n",
    "         score_gb_train]\n",
    "    )\n",
    "    scores_train = scores_train.sort_values(by = 'recall', ascending=False)    \n",
    "        \n",
    "    # make dataframe with predictions\n",
    "    predictions = pd.DataFrame({\n",
    "        'actuals':y_test,\n",
    "        'pred_knn':pred_labels_knn,\n",
    "        'pred_logistic_regression':pred_labels_lr,\n",
    "        'pred_bernoulli_naive_bayes':pred_labels_bnb,\n",
    "        'pred_gaussian_naive_bayes':pred_labels_gnb,\n",
    "        'pred_random_forest':pred_labels_rf,\n",
    "        'pred_decision_tree':pred_labels_dt,\n",
    "        'pred_gradient_boosting_classifier':pred_labels_gb\n",
    "    })\n",
    "\n",
    "    return scores, predictions, scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['times_with_12plus_alc',\n",
       " 'seen_mental_health_professional',\n",
       " 'count_days_seen_doctor_12mo',\n",
       " 'count_lost_10plus_pounds',\n",
       " 'arthritis',\n",
       " 'horomones_not_bc',\n",
       " 'is_usa_born',\n",
       " 'times_with_8plus_alc',\n",
       " 'time_since_last_healthcare',\n",
       " 'duration_last_healthcare_visit',\n",
       " 'work_schedule',\n",
       " 'age_in_years',\n",
       " 'regular_periods',\n",
       " 'count_minutes_moderate_sedentary_activity',\n",
       " 'emergency_food_received',\n",
       " 'high_bp',\n",
       " 'dr_recommend_exercise',\n",
       " 'metal_objects',\n",
       " 'drank_alc',\n",
       " 'cholesterol_prescription',\n",
       " 'smoked_100_cigs',\n",
       " 'vigorous_recreation',\n",
       " 'dr_recommend_lose_weight',\n",
       " 'cancer',\n",
       " 'chest_discomfort',\n",
       " 'has_health_insurance',\n",
       " 'have_health_insurance',\n",
       " 'weight_lbs',\n",
       " 'high_cholesterol']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_columns = candidate_features.copy()\n",
    "cor_columns.append('MDD')\n",
    "\n",
    "cdc_survey_pmom['num_dep_screener_0'] = (cdc_survey_pmom[dep_screener_cols]==0).sum(axis=1)\n",
    "\n",
    "# find columns where top feature is 0\n",
    "#df_to_use = cdc_survey_pmom[cdc_survey_pmom['feeling_down_depressed_hopeless'] == 0]\n",
    "df_to_use = cdc_survey_pmom[cdc_survey_pmom['num_dep_screener_0'] >= 9]\n",
    "\n",
    "correlation_matrix = df_to_use[cor_columns].corr(method='pearson')\n",
    "correlation_values_abs = abs(correlation_matrix['MDD']).sort_values(ascending=False)\n",
    "correlation_values_abs = correlation_values_abs[correlation_values_abs.notna()]\n",
    "\n",
    "top_additional_candidates_v2 = list(correlation_values_abs[1:30].index)\n",
    "top_additional_candidates_v2 = [col for col in top_additional_candidates_v2 if col not in dep_screener_cols]\n",
    "top_additional_candidates_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['little_interest_in_doing_things', 'feeling_down_depressed_hopeless', 'trouble_falling_or_staying_asleep', 'feeling_tired_or_having_little_energy', 'poor_appetitie_or_overeating', 'feeling_bad_about_yourself', 'trouble_concentrating', 'moving_or_speaking_to_slowly_or_fast', 'thoughts_you_would_be_better_off_dead', 'difficult_doing_daytoday_tasks', 'times_with_12plus_alc', 'seen_mental_health_professional', 'count_days_seen_doctor_12mo', 'count_lost_10plus_pounds', 'arthritis', 'horomones_not_bc', 'is_usa_born', 'times_with_8plus_alc', 'time_since_last_healthcare', 'duration_last_healthcare_visit', 'work_schedule', 'age_in_years', 'regular_periods', 'count_minutes_moderate_sedentary_activity', 'emergency_food_received', 'high_bp', 'dr_recommend_exercise', 'metal_objects', 'drank_alc', 'cholesterol_prescription', 'smoked_100_cigs', 'vigorous_recreation', 'dr_recommend_lose_weight', 'cancer', 'chest_discomfort', 'has_health_insurance', 'have_health_insurance', 'weight_lbs', 'readytoeat_meals', 'regular_healthcare_place', 'try_pregnancy_1yr', 'currently_increase_exercise', 'coronary_heart_disease', 'stroke', 'heart_attack', 'see_dr_fertility']\n"
     ]
    }
   ],
   "source": [
    "print(model_features + [\n",
    "    'readytoeat_meals',\n",
    "    'regular_healthcare_place',\n",
    "    'try_pregnancy_1yr',\n",
    "    'currently_increase_exercise',\n",
    "    'coronary_heart_disease',\n",
    "    'stroke',\n",
    "    'heart_attack',\n",
    "    'see_dr_fertility'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.954623</td>\n",
       "      <td>0.278215</td>\n",
       "      <td>0.78825</td>\n",
       "      <td>0.616419</td>\n",
       "      <td>0.885192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.802158</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.78825</td>\n",
       "      <td>0.734412</td>\n",
       "      <td>0.788250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.871775</td>\n",
       "      <td>0.392593</td>\n",
       "      <td>0.78825</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.822588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1390.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>0.78825</td>\n",
       "      <td>1549.000000</td>\n",
       "      <td>1549.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1  accuracy    macro avg  weighted avg\n",
       "precision     0.954623    0.278215   0.78825     0.616419      0.885192\n",
       "recall        0.802158    0.666667   0.78825     0.734412      0.788250\n",
       "f1-score      0.871775    0.392593   0.78825     0.632184      0.822588\n",
       "support    1390.000000  159.000000   0.78825  1549.000000   1549.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = get_model_data(\n",
    "    original_df = cdc_survey_pmom,\n",
    "    columns = model_features + [\n",
    "    'readytoeat_meals',\n",
    "    'regular_healthcare_place',\n",
    "    'try_pregnancy_1yr',\n",
    "    'currently_increase_exercise',\n",
    "    'coronary_heart_disease',\n",
    "    'stroke',\n",
    "    'heart_attack',\n",
    "    'see_dr_fertility'\n",
    "]\n",
    ")\n",
    "\n",
    "processing_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'), RobustScaler(), GaussianNB())\n",
    "      \n",
    "processing_pipeline.fit(x_train, y_train)\n",
    "y_pred  = processing_pipeline.predict(x_test)\n",
    "# y_pred = [x.round() for x in y_pred]\n",
    "df_gnb = pd.DataFrame(classification_report(\n",
    "            y_test, \n",
    "            y_pred, \n",
    "            # target_names=target_names, \n",
    "            output_dict=True\n",
    "))\n",
    "df_gnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export GNB model to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>algo</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.616419</td>\n",
       "      <td>0.734412</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>0.78825</td>\n",
       "      <td>0.784238</td>\n",
       "      <td>0.78825</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1e-09}</td>\n",
       "      <td>106</td>\n",
       "      <td>275</td>\n",
       "      <td>53</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                  algo precision    recall  f1-score support  accuracy  \\\n",
       "0       Gaussian Naive Bayes  0.616419  0.734412  0.632184  1549.0   0.78825   \n",
       "\n",
       "metric  train_r2  test_r2                           best_params   tp   fn  fp  \\\n",
       "0       0.784238  0.78825  {'gaussiannb__var_smoothing': 1e-09}  106  275  53   \n",
       "\n",
       "metric    tn  \n",
       "0       1115  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = get_model_data(\n",
    "    original_df = cdc_survey_pmom,\n",
    "    columns = model_features + [\n",
    "                'readytoeat_meals',\n",
    "                'regular_healthcare_place',\n",
    "                'try_pregnancy_1yr',\n",
    "                'currently_increase_exercise',\n",
    "                'coronary_heart_disease',\n",
    "                'stroke',\n",
    "                'heart_attack',\n",
    "                'see_dr_fertility'\n",
    "            ]\n",
    ")\n",
    "\n",
    "baseline_models(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    x_test, \n",
    "    y_test, \n",
    "    algo_attempt_list=['gnb'],\n",
    "    grid_search=True,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    imputer=SimpleImputer(strategy='most_frequent'),#SimpleImputer(),\n",
    "    scaler=RobustScaler(),\n",
    "    bin_vars=True,\n",
    "    score_on='recall',\n",
    "    do_smote=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:01<02:29,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best score is: 0.734052757793765\n",
      "got better with None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:34<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734052757793765\n",
      "[]\n",
      "[None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>algo</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>best_params</th>\n",
       "      <th>tp</th>\n",
       "      <th>...</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>imputer</th>\n",
       "      <th>scaler</th>\n",
       "      <th>score_on</th>\n",
       "      <th>extra_random_feature</th>\n",
       "      <th>cv</th>\n",
       "      <th>features</th>\n",
       "      <th>trial_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.616036</td>\n",
       "      <td>0.734053</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>0.787605</td>\n",
       "      <td>0.785368</td>\n",
       "      <td>0.787605</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 2.31012970008315...</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>1114</td>\n",
       "      <td>False</td>\n",
       "      <td>SimpleImputer(strategy='most_frequent')</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>recall</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>['algo', 'precision', 'recall', 'f1-score', 's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                  algo precision    recall f1-score support  accuracy  \\\n",
       "0       Gaussian Naive Bayes  0.616036  0.734053   0.6316  1549.0  0.787605   \n",
       "\n",
       "metric  train_r2   test_r2                                        best_params  \\\n",
       "0       0.785368  0.787605  {'gaussiannb__var_smoothing': 2.31012970008315...   \n",
       "\n",
       "metric   tp  ...  fp    tn  SMOTE                                  imputer  \\\n",
       "0       106  ...  53  1114  False  SimpleImputer(strategy='most_frequent')   \n",
       "\n",
       "metric          scaler score_on extra_random_feature cv  \\\n",
       "0       RobustScaler()   recall                 None  3   \n",
       "\n",
       "metric                                           features trial_num  \n",
       "0       ['algo', 'precision', 'recall', 'f1-score', 's...         1  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### with all setting each trial takes a while ##########\n",
    "##### commenting out options can make bring iteration time down drastically ###########\n",
    "num_trials = 100\n",
    "best_score = 0\n",
    "\n",
    "primary_eval_metric = 'recall'\n",
    "secondary_eval_metric = 'f1-score'\n",
    "# primary_eval_metric = 'f1-score'\n",
    "# secondary_eval_metric = 'recall'\n",
    "\n",
    "best_cols = []\n",
    "df_best_scores = pd.DataFrame()\n",
    "df_all_scores = pd.DataFrame()\n",
    "extra_selected_feats = []\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in tqdm(range(1, num_trials+1)):\n",
    "        random_feats_list = [col for col in candidate_features if col not in model_features+extra_selected_feats]\n",
    "        random_feat = random_feats_list[random.randint(0, len(random_feats_list)-1)]\n",
    "        \n",
    "        if i == 1:\n",
    "            feats_to_use = model_features + [\n",
    "                # 'gallbladder_surgery'\n",
    "                # , 'has_diabetes'\n",
    "                # ,'readytoeat_meals'\n",
    "                # , 'regular_healthcare_place'\n",
    "                'try_pregnancy_1yr'\n",
    "                , 'currently_increase_exercise'\n",
    "                , 'coronary_heart_disease'\n",
    "                , 'stroke'\n",
    "                , 'heart_attack'\n",
    "                , 'monthly_poverty_index'\n",
    "                , 'see_dr_fertility'\n",
    "                , 'high_bp_prescription'\n",
    "            ]\n",
    "            random_feat = None\n",
    "        else:\n",
    "            feats_to_use = model_features + [random_feat] +  [\n",
    "                # 'gallbladder_surgery'\n",
    "                # , 'has_diabetes'\n",
    "                # ,'readytoeat_meals'\n",
    "                # , 'regular_healthcare_place'\n",
    "                'try_pregnancy_1yr'\n",
    "                , 'currently_increase_exercise'\n",
    "                , 'coronary_heart_disease'\n",
    "                , 'stroke'\n",
    "                , 'heart_attack'\n",
    "                , 'monthly_poverty_index'\n",
    "                , 'see_dr_fertility'\n",
    "                , 'high_bp_prescription'\n",
    "            ]\n",
    "\n",
    "        x_train, x_test, y_train, y_test = get_model_data(\n",
    "            original_df = cdc_survey_pmom,\n",
    "            columns = feats_to_use\n",
    "        )\n",
    "\n",
    "        # SMOTE or not\n",
    "        for b in [False]:#]:\n",
    "            # different imputers\n",
    "            for imp in [SimpleImputer(strategy='most_frequent')]:#[None, KNNImputer(), SimpleImputer(strategy='mean'), SimpleImputer(strategy='most_frequent')]:\n",
    "                for scl in [RobustScaler()]:#[None, RobustScaler(), StandardScaler(), MinMaxScaler(), Normalizer()]:\n",
    "                    for cv in [3]:#, 5, RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)]:\n",
    "                        # print(b, imp, scl, cv)\n",
    "                        df_scores = baseline_models(\n",
    "                            x_train, \n",
    "                            y_train, \n",
    "                            x_test, \n",
    "                            y_test, \n",
    "                            algo_attempt_list=['gnb'],\n",
    "                            grid_search=True,\n",
    "                            cv=3,\n",
    "                            verbose=0,\n",
    "                            imputer=imp,\n",
    "                            scaler=scl,\n",
    "                            do_smote=b,\n",
    "                            bin_vars=False,\n",
    "                            score_on=primary_eval_metric\n",
    "                            )\n",
    "\n",
    "                        df_scores['SMOTE'] = b\n",
    "                        df_scores['imputer'] = imp\n",
    "                        df_scores['scaler'] = scl\n",
    "                        df_scores['score_on'] = primary_eval_metric\n",
    "                        df_scores['extra_random_feature'] = random_feat\n",
    "                        df_scores['cv'] = cv\n",
    "                        # sort to keep best\n",
    "                        df_scores.sort_values(\n",
    "                            by=[primary_eval_metric, secondary_eval_metric], \n",
    "                            inplace=True, \n",
    "                            ascending=False\n",
    "                        )\n",
    "                        df_scores = df_scores.reset_index()\n",
    "                        df_scores = df_scores.iloc[:,1:]\n",
    "                        df_all_scores = pd.concat([df_all_scores, df_scores], ignore_index=True)\n",
    "                        if df_scores[primary_eval_metric][0] > best_score:\n",
    "                            print(f'new best score is: {df_scores[primary_eval_metric][0]}')\n",
    "                            print(f'got better with {random_feat}')\n",
    "                            best_score = df_scores[primary_eval_metric][0]\n",
    "                            extra_selected_feats.extend([random_feat])\n",
    "                            best_f1 = df_scores[primary_eval_metric][0]\n",
    "                            # best_cols = df_random_feats.columns\n",
    "                            df_scores['features'] = str(df_scores.columns.tolist())\n",
    "                            df_scores['trial_num'] = i\n",
    "                            df_best_scores = pd.concat([df_best_scores, df_scores.iloc[0:1,:]], ignore_index=True)\n",
    "except KeyboardInterrupt as e:\n",
    "    print(e)\n",
    "\n",
    "df_best_scores.sort_values(\n",
    "    by=[primary_eval_metric, secondary_eval_metric], \n",
    "    inplace=True, \n",
    "    ascending=False\n",
    ")\n",
    "df_all_scores.sort_values(\n",
    "    by=[primary_eval_metric, secondary_eval_metric], \n",
    "    inplace=True, \n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "df_best_scores = df_best_scores.reset_index(drop=True)\n",
    "print(best_f1)\n",
    "print(best_cols)\n",
    "print(extra_selected_feats)\n",
    "df_best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_random_feats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m df_scores[primary_eval_metric][\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m best_score:\n\u001b[1;32m     78\u001b[0m     best_f1 \u001b[39m=\u001b[39m df_scores[primary_eval_metric][\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 79\u001b[0m     best_cols \u001b[39m=\u001b[39m df_random_feats\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m     80\u001b[0m     df_scores[\u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(df_random_feats\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m     81\u001b[0m     df_scores[\u001b[39m'\u001b[39m\u001b[39mtrial_num\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m i\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_random_feats' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### with all setting each trial takes a while ##########\n",
    "##### commenting out options can make bring iteration time down drastically ###########\n",
    "num_trials = 100\n",
    "best_score = 0\n",
    "\n",
    "primary_eval_metric = 'recall'\n",
    "secondary_eval_metric = 'f1-score'\n",
    "# primary_eval_metric = 'f1-score'\n",
    "# secondary_eval_metric = 'recall'\n",
    "\n",
    "best_cols = []\n",
    "df_best_scores = pd.DataFrame()\n",
    "df_all_scores = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in tqdm(range(1, num_trials+1)):\n",
    "        random_feats_list = [col for col in candidate_features if col not in model_features]\n",
    "        random_feat = random_feats_list[random.randint(0, len(random_feats_list)-1)]\n",
    "        \n",
    "        if i == 1:\n",
    "            feats_to_use = model_features\n",
    "            random_feat = None\n",
    "        else:\n",
    "            feats_to_use = model_features + [random_feat]\n",
    "\n",
    "        x_train, x_test, y_train, y_test = get_model_data(\n",
    "            original_df = cdc_survey_pmom,\n",
    "            columns = feats_to_use\n",
    "        )\n",
    "\n",
    "        # SMOTE or not\n",
    "        for b in [False]:#]:\n",
    "            # different imputers\n",
    "            for imp in [None]:#, KNNImputer(), SimpleImputer(strategy='mean'), SimpleImputer(strategy='most_frequent')]:\n",
    "                for scl in [None]:#, RobustScaler(), StandardScaler(), MinMaxScaler(), Normalizer()]:\n",
    "                    for cv in [3]:#, 5, RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)]:\n",
    "                        # print(b, imp, scl, cv)\n",
    "                        df_scores = baseline_models(\n",
    "                            x_train, \n",
    "                            y_train, \n",
    "                            x_test, \n",
    "                            y_test, \n",
    "                            algo_attempt_list=['gnb'],\n",
    "                            grid_search=True,\n",
    "                            cv=3,\n",
    "                            verbose=0,\n",
    "                            imputer=imp,\n",
    "                            scaler=scl,\n",
    "                            do_smote=b,\n",
    "                            bin_vars=False,\n",
    "                            score_on=primary_eval_metric\n",
    "                            )\n",
    "\n",
    "                        df_scores['SMOTE'] = b\n",
    "                        df_scores['imputer'] = imp\n",
    "                        df_scores['scaler'] = scl\n",
    "                        df_scores['score_on'] = primary_eval_metric\n",
    "                        df_scores['extra_random_feature'] = random_feat\n",
    "                        df_scores['cv'] = cv\n",
    "                        # sort to keep best\n",
    "                        df_scores.sort_values(\n",
    "                            by=[primary_eval_metric, secondary_eval_metric], \n",
    "                            inplace=True, \n",
    "                            ascending=False\n",
    "                        )\n",
    "                        df_scores = df_scores.reset_index()\n",
    "                        df_scores = df_scores.iloc[:,1:]\n",
    "                        df_all_scores = pd.concat([df_all_scores, df_scores], ignore_index=True)\n",
    "                        if df_scores[primary_eval_metric][0] > best_score:\n",
    "                            best_f1 = df_scores[primary_eval_metric][0]\n",
    "                            best_cols = df_random_feats.columns\n",
    "                            df_scores['features'] = str(df_random_feats.columns.tolist())\n",
    "                            df_scores['trial_num'] = i\n",
    "                            df_best_scores = pd.concat([df_best_scores, df_scores.iloc[0:1,:]], ignore_index=True)\n",
    "except KeyboardInterrupt as e:\n",
    "    print(e)\n",
    "\n",
    "df_best_scores.sort_values(\n",
    "    by=[primary_eval_metric, secondary_eval_metric], \n",
    "    inplace=True, \n",
    "    ascending=False\n",
    ")\n",
    "df_all_scores.sort_values(\n",
    "    by=[primary_eval_metric, secondary_eval_metric], \n",
    "    inplace=True, \n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "df_best_scores = df_best_scores.reset_index(drop=True)\n",
    "print(best_f1)\n",
    "print(best_cols)\n",
    "df_best_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = get_model_data(\n",
    "#     original_df = cdc_survey_pmom,\n",
    "#     columns = dep_screener_cols + \n",
    "#               top_additional_candidates_v2[:28]\n",
    "# )\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# performance_test, predictions, performance_train = generate_models(\n",
    "#     x_train, \n",
    "#     y_train, \n",
    "#     x_test, \n",
    "#     y_test\n",
    "# )\n",
    "\n",
    "# #baseline_model_summary_attempt1 = baseline_model_attempt1[baseline_model_attempt1['grouping'] == 'depressed_yes']\n",
    "# performance_test_macro = performance_test[performance_test['grouping'] == 'macro_avg']\n",
    "# performance_test_mdd1 = performance_test[performance_test['grouping'] == 'depressed_yes']\n",
    "# performance_test_macro[['model','recall','f1-score','precision','accuracy']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
