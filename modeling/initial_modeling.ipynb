{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import mod\n",
    "from os import getcwd\n",
    "from os.path import exists, join\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import pickle\n",
    "from IPython.display import Image\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SEQN</th>\n",
       "      <th>ALQ111</th>\n",
       "      <th>ALQ121</th>\n",
       "      <th>ALQ130</th>\n",
       "      <th>ALQ142</th>\n",
       "      <th>ALQ270</th>\n",
       "      <th>ALQ280</th>\n",
       "      <th>ALQ290</th>\n",
       "      <th>ALQ151</th>\n",
       "      <th>...</th>\n",
       "      <th>has_health_insurance</th>\n",
       "      <th>has_health_insurance_gap</th>\n",
       "      <th>has_smoked_tabacco_last_5days</th>\n",
       "      <th>is_male</th>\n",
       "      <th>is_usa_born</th>\n",
       "      <th>has_diabetes</th>\n",
       "      <th>has_overweight_diagnosis</th>\n",
       "      <th>has_tried_to_lose_weight_12mo</th>\n",
       "      <th>has_been_pregnant</th>\n",
       "      <th>monthly_poverty_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>109284.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>109290.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>109291.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>109295.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>109300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>8950</td>\n",
       "      <td>124802.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>8951</td>\n",
       "      <td>124803.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8957</th>\n",
       "      <td>8957</td>\n",
       "      <td>124812.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8958</th>\n",
       "      <td>8958</td>\n",
       "      <td>124813.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>8961</td>\n",
       "      <td>124817.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3412 rows × 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      SEQN  ALQ111        ALQ121  ALQ130        ALQ142  \\\n",
       "5              5  109284.0     2.0           NaN     NaN           NaN   \n",
       "7              7  109290.0     1.0  5.397605e-79     NaN           NaN   \n",
       "8              8  109291.0     2.0           NaN     NaN           NaN   \n",
       "11            11  109295.0     2.0           NaN     NaN           NaN   \n",
       "14            14  109300.0     1.0  5.397605e-79     NaN           NaN   \n",
       "...          ...       ...     ...           ...     ...           ...   \n",
       "8950        8950  124802.0     1.0  5.397605e-79     NaN           NaN   \n",
       "8951        8951  124803.0     2.0           NaN     NaN           NaN   \n",
       "8957        8957  124812.0     1.0  6.000000e+00     3.0  8.000000e+00   \n",
       "8958        8958  124813.0     1.0  5.397605e-79     NaN           NaN   \n",
       "8961        8961  124817.0     1.0  3.000000e+00     2.0  5.397605e-79   \n",
       "\n",
       "      ALQ270  ALQ280        ALQ290  ALQ151  ...  has_health_insurance  \\\n",
       "5        NaN     NaN           NaN     NaN  ...                   0.0   \n",
       "7        NaN     NaN           NaN     2.0  ...                   1.0   \n",
       "8        NaN     NaN           NaN     NaN  ...                   1.0   \n",
       "11       NaN     NaN           NaN     NaN  ...                   1.0   \n",
       "14       NaN     NaN           NaN     2.0  ...                   1.0   \n",
       "...      ...     ...           ...     ...  ...                   ...   \n",
       "8950     NaN     NaN           NaN     2.0  ...                   1.0   \n",
       "8951     NaN     NaN           NaN     NaN  ...                   1.0   \n",
       "8957    10.0     9.0  5.397605e-79     2.0  ...                   0.0   \n",
       "8958     NaN     NaN           NaN     2.0  ...                   1.0   \n",
       "8961     NaN     NaN           NaN     2.0  ...                   1.0   \n",
       "\n",
       "      has_health_insurance_gap  has_smoked_tabacco_last_5days  is_male  \\\n",
       "5                          NaN                            0.0        0   \n",
       "7                          0.0                            0.0        0   \n",
       "8                          0.0                            0.0        0   \n",
       "11                         0.0                            0.0        0   \n",
       "14                         0.0                            0.0        0   \n",
       "...                        ...                            ...      ...   \n",
       "8950                       0.0                            0.0        0   \n",
       "8951                       0.0                            0.0        0   \n",
       "8957                       NaN                            0.0        0   \n",
       "8958                       1.0                            0.0        0   \n",
       "8961                       0.0                            0.0        0   \n",
       "\n",
       "      is_usa_born  has_diabetes  has_overweight_diagnosis  \\\n",
       "5             0.0           0.0                       1.0   \n",
       "7             1.0           1.0                       0.0   \n",
       "8             1.0           0.0                       1.0   \n",
       "11            0.0           0.0                       0.0   \n",
       "14            0.0           0.0                       0.0   \n",
       "...           ...           ...                       ...   \n",
       "8950          0.0           0.0                       0.0   \n",
       "8951          0.0           1.0                       0.0   \n",
       "8957          1.0           0.0                       0.0   \n",
       "8958          0.0           0.0                       0.0   \n",
       "8961          0.0           1.0                       1.0   \n",
       "\n",
       "      has_tried_to_lose_weight_12mo  has_been_pregnant  monthly_poverty_index  \n",
       "5                               1.0                1.0                    NaN  \n",
       "7                               1.0                1.0                   4.80  \n",
       "8                               0.0                1.0                    NaN  \n",
       "11                              0.0                1.0                   4.37  \n",
       "14                              1.0                1.0                   2.89  \n",
       "...                             ...                ...                    ...  \n",
       "8950                            0.0                1.0                    NaN  \n",
       "8951                            0.0                1.0                   1.18  \n",
       "8957                            0.0                1.0                   3.66  \n",
       "8958                            1.0                1.0                    NaN  \n",
       "8961                            1.0                1.0                   1.82  \n",
       "\n",
       "[3412 rows x 437 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdc_survey = pd.read_csv('../data/cdc_nhanes_survey_responses_clean.csv')\n",
    "\n",
    "# filter to pregnant moms\n",
    "cdc_survey_pmom = cdc_survey[cdc_survey['has_been_pregnant'] == 1]\n",
    "cdc_survey_pmom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = [\n",
    "    # Target\n",
    "    'MDD',\n",
    "    # Depression screener\n",
    "    'little_interest_in_doing_things',\n",
    "    'feeling_down_depressed_hopeless',\n",
    "    'trouble_falling_or_staying_asleep',\n",
    "    'feeling_tired_or_having_little_energy',\n",
    "    'poor_appetitie_or_overeating',\n",
    "    'feeling_bad_about_yourself',\n",
    "    'trouble_concentrating',\n",
    "    'moving_or_speaking_to_slowly_or_fast',\n",
    "    'thoughts_you_would_be_better_off_dead',\n",
    "    'difficult_doing_daytoday_tasks',\n",
    "    # Alcohol & smoking\n",
    "    'has_smoked_tabacco_last_5days',\n",
    "    'alcoholic_drinks_past_12mo',    \n",
    "    # Diet & Nutrition\n",
    "    'how_healthy_is_your_diet',    \n",
    "    'count_lost_10plus_pounds',\n",
    "    'has_tried_to_lose_weight_12mo',       \n",
    "    # Physical health & Medical History\n",
    "    'count_days_seen_doctor_12mo',\n",
    "    'duration_last_healthcare_visit',        \n",
    "    'count_days_moderate_recreational_activity',   \n",
    "    'count_minutes_moderate_recreational_activity',\n",
    "    'count_minutes_moderate_sedentary_activity',\n",
    "    'general_health_condition',    \n",
    "    'has_diabetes',\n",
    "    'has_overweight_diagnosis',         \n",
    "    # Demographic data\n",
    "    'food_security_level_household',   \n",
    "    'food_security_level_adult',    \n",
    "    'monthly_poverty_index_category',\n",
    "    'monthly_poverty_index',\n",
    "    'count_hours_worked_last_week',\n",
    "    'age_in_years',   \n",
    "    'education_level',\n",
    "    'is_usa_born',    \n",
    "    'has_health_insurance',\n",
    "    'has_health_insurance_gap'   \n",
    "]\n",
    "len(all_columns)\n",
    "\n",
    "# cols removed since all null\n",
    "# count_tried_to_lose_weight_youth\n",
    "# count_days_physical_activity_youth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find columns where everything is null\n",
    "# need to delete those\n",
    "#cdc_survey_pmom = cdc_survey_pmom[all_columns]\n",
    "#columns = cdc_survey_pmom.columns[cdc_survey_pmom.notnull().any() == False]\n",
    "#columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test & Train Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(original_df, columns, test_size_prop=0.2):\n",
    "    \"\"\"\n",
    "    Function to build feature & indicator matrices for both train & test.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_to_use = original_df[columns]\n",
    "    \n",
    "    # Create test & train data\n",
    "    x = df_to_use.iloc[:,1:].values\n",
    "    y = df_to_use['MDD'].values\n",
    "    \n",
    "    # SimpleImputer() = fill in missing values\n",
    "    # note imputer may drop columns if no values exist for it\n",
    "    imputer = SimpleImputer(strategy='median')  \n",
    "    x = imputer.fit_transform(x)\n",
    "\n",
    "    # RobustScaler() = scale features to remove outliers\n",
    "    trans = RobustScaler()\n",
    "    x = trans.fit_transform(x)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, \n",
    "        y, \n",
    "        test_size=test_size_prop, \n",
    "        random_state=42\n",
    "    ) \n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, pred_labels):\n",
    "    \"\"\"\n",
    "    Function that displays a confusion matrix for provided true and predicted classes\n",
    "    \"\"\"\n",
    "    #print(f'cover type 1 and type 2 total correct {np.sum(np.diag(metrics.confusion_matrix(y_test, pred_labels))[:2])}')\n",
    "\n",
    "    cm = confusion_matrix(y_test, pred_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    disp = disp.plot(include_values=True, cmap='viridis', ax=ax, xticks_rotation='horizontal')    \n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def get_performance_df(label_actual, label_pred, index_label):\n",
    "    \"\"\"\n",
    "    Function to calculate performance metrics for model.\n",
    "    Includes precision, recal, F1, & support.\n",
    "    \"\"\"\n",
    "    performance_report = classification_report(label_actual, label_pred, output_dict=True)\n",
    "    performance_report = performance_report['macro avg']\n",
    "    result_table = pd.DataFrame(performance_report, index = [index_label])\n",
    "    return result_table\n",
    "\n",
    "def baseline_models(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    x_test, \n",
    "    y_test,\n",
    "    do_smote=True,\n",
    "    show_confusion_matrix=False,\n",
    "    show_score_dataframe=False):\n",
    "    \"\"\"\n",
    "    Function that trains and makes predictions using 5 of the classifiers went over during the class.\n",
    "    Meant as a helper function for easier testing of different modeling pipelines.\n",
    "    \"\"\"\n",
    "\n",
    "    #  do_smote\n",
    "    if do_smote == True:\n",
    "        sm = SMOTE(random_state=42)\n",
    "        x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "\n",
    "    # K-Nearest Neighbors\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred_labels_knn  = knn.predict(x_test)\n",
    "    score_knn = get_performance_df(y_test, pred_labels_knn,'Knn')\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lm = LogisticRegression()\n",
    "    lm.fit(x_train, y_train)\n",
    "    pred_labels_lr  = lm.predict(x_test)\n",
    "    score_lr = get_performance_df(y_test, pred_labels_lr,'Logistic Regression')\n",
    "        \n",
    "    # Bernoulii Naive Bayes\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(x_train, y_train)\n",
    "    pred_labels_bnb  = bnb.predict(x_test)\n",
    "    score_bnb = get_performance_df(y_test, pred_labels_bnb,'Bernoulli Naive Bayes')    \n",
    "        \n",
    "    # Gaussian Naive Bayes\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    pred_labels_gnb  = gnb.predict(x_test)\n",
    "    score_gnb = get_performance_df(y_test, pred_labels_gnb,'Gaussian Naive Bayes')    \n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(random_state=0)\n",
    "    rf.fit(x_train, y_train)\n",
    "    pred_labels_rf  = rf.predict(x_test)\n",
    "    predictions_posterior_rf = rf.predict_proba(x_test)\n",
    "    score_rf = get_performance_df(y_test, pred_labels_rf,'Random Forest')      \n",
    "\n",
    "    # make dataframe with scores\n",
    "    scores = pd.concat([score_knn, score_lr, score_bnb, score_gnb, score_rf])\n",
    "    scores = scores.sort_values(by = 'recall', ascending=False)\n",
    "    \n",
    "    if show_score_dataframe:\n",
    "        display(scores.style.set_table_attributes('style=\"font-size: 17px\"').hide_index())\n",
    "    \n",
    "    if show_confusion_matrix:\n",
    "        print('\\nK-Nearest Neighbors Confusion Matrix')\n",
    "        plot_confusion_matrix(y_test, pred_labels_knn)\n",
    "        print('Logistic Regression Confusion Matrix')\n",
    "        plot_confusion_matrix(y_test, pred_labels_lr)\n",
    "        print('Bernoulli Naive Bayes Confusion Matrix')\n",
    "        plot_confusion_matrix(y_test, pred_labels_bnb)\n",
    "        print('Gaussian Naive Bayes Confusion Matrix')\n",
    "        plot_confusion_matrix(y_test, pred_labels_gnb)\n",
    "        print('Random Forest Confusion Matrix')\n",
    "        plot_confusion_matrix(y_test, pred_labels_rf)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline models (just depression screener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2729, 10)\n",
      "(683, 10)\n",
      "(2729,)\n",
      "(683,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = get_model_data(\n",
    "    original_df = cdc_survey_pmom,\n",
    "    columns = all_columns[0:11] # just depression screener\n",
    ")\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.609595</td>\n",
       "      <td>0.672248</td>\n",
       "      <td>0.627428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.619179</td>\n",
       "      <td>0.657007</td>\n",
       "      <td>0.633433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.653195</td>\n",
       "      <td>0.524981</td>\n",
       "      <td>0.525183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.552096</td>\n",
       "      <td>0.512648</td>\n",
       "      <td>0.506990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn</th>\n",
       "      <td>0.516733</td>\n",
       "      <td>0.506154</td>\n",
       "      <td>0.500418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall  f1-score\n",
       "Bernoulli Naive Bayes   0.609595  0.672248  0.627428\n",
       "Gaussian Naive Bayes    0.619179  0.657007  0.633433\n",
       "Logistic Regression     0.653195  0.524981  0.525183\n",
       "Random Forest           0.552096  0.512648  0.506990\n",
       "Knn                     0.516733  0.506154  0.500418"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = baseline_models(x_train, y_train, x_test, y_test, do_smote=False)\n",
    "baseline_model[['precision','recall','f1-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.590391</td>\n",
       "      <td>0.687960</td>\n",
       "      <td>0.598980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.587726</td>\n",
       "      <td>0.677093</td>\n",
       "      <td>0.597050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.600932</td>\n",
       "      <td>0.675809</td>\n",
       "      <td>0.617413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn</th>\n",
       "      <td>0.587408</td>\n",
       "      <td>0.638338</td>\n",
       "      <td>0.600637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.510287</td>\n",
       "      <td>0.505500</td>\n",
       "      <td>0.502845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall  f1-score\n",
       "Logistic Regression     0.590391  0.687960  0.598980\n",
       "Bernoulli Naive Bayes   0.587726  0.677093  0.597050\n",
       "Gaussian Naive Bayes    0.600932  0.675809  0.617413\n",
       "Knn                     0.587408  0.638338  0.600637\n",
       "Random Forest           0.510287  0.505500  0.502845"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model_with_smote = baseline_models(x_train, y_train, x_test, y_test, do_smote=True)\n",
    "baseline_model_with_smote[['precision','recall','f1-score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline models (all variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2729, 33)\n",
      "(683, 33)\n",
      "(2729,)\n",
      "(683,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = get_model_data(\n",
    "    original_df = cdc_survey_pmom,\n",
    "    columns = all_columns\n",
    ")\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.620125</td>\n",
       "      <td>0.688796</td>\n",
       "      <td>0.640166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.613735</td>\n",
       "      <td>0.664627</td>\n",
       "      <td>0.630484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.588745</td>\n",
       "      <td>0.515895</td>\n",
       "      <td>0.510511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn</th>\n",
       "      <td>0.552096</td>\n",
       "      <td>0.512648</td>\n",
       "      <td>0.506990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.450808</td>\n",
       "      <td>0.498377</td>\n",
       "      <td>0.473400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall  f1-score\n",
       "Bernoulli Naive Bayes   0.620125  0.688796  0.640166\n",
       "Gaussian Naive Bayes    0.613735  0.664627  0.630484\n",
       "Logistic Regression     0.588745  0.515895  0.510511\n",
       "Knn                     0.552096  0.512648  0.506990\n",
       "Random Forest           0.450808  0.498377  0.473400"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = baseline_models(x_train, y_train, x_test, y_test, do_smote=False)\n",
    "baseline_model[['precision','recall','f1-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.594492</td>\n",
       "      <td>0.700451</td>\n",
       "      <td>0.603120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.586315</td>\n",
       "      <td>0.687306</td>\n",
       "      <td>0.590851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.598842</td>\n",
       "      <td>0.674186</td>\n",
       "      <td>0.614727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knn</th>\n",
       "      <td>0.566361</td>\n",
       "      <td>0.657116</td>\n",
       "      <td>0.555784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.641773</td>\n",
       "      <td>0.536659</td>\n",
       "      <td>0.544620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       precision    recall  f1-score\n",
       "Logistic Regression     0.594492  0.700451  0.603120\n",
       "Gaussian Naive Bayes    0.586315  0.687306  0.590851\n",
       "Bernoulli Naive Bayes   0.598842  0.674186  0.614727\n",
       "Knn                     0.566361  0.657116  0.555784\n",
       "Random Forest           0.641773  0.536659  0.544620"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = baseline_models(x_train, y_train, x_test, y_test, do_smote=True)\n",
    "baseline_model[['precision','recall','f1-score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperprameter grid search\n",
    "SVG is terrible, but need to do some gridsearch on above baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/orencarmeli/Desktop/capstone210-ppd-carmeli_chari_hand_lee/modeling/model_pipeline.pkl\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Train R^2 Score : 0.514\n",
      "Test R^2 Score : -0.013\n",
      "Best R^2 Score Through Grid Search : 0.039\n",
      "Best Parameters : {'robustscaler__quantile_range': (25.0, 75.0), 'simpleimputer__strategy': 'median', 'svr__C': 1.0, 'svr__gamma': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model Pipeline\n",
    "processing_pipeline = make_pipeline(SimpleImputer(), RobustScaler(), SVR())\n",
    "\n",
    "params = {\n",
    "    \"simpleimputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"robustscaler__quantile_range\": [(25.0, 75.0), (30.0, 70.0)],\n",
    "    \"svr__C\": [0.1, 1.0],\n",
    "    \"svr__gamma\": [\"auto\", 0.1],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(processing_pipeline, param_grid=params, n_jobs=-1, cv=5, verbose=3)\n",
    "\n",
    "model_filename = \"model_pipeline.pkl\"\n",
    "model_path = join(getcwd(), model_filename)\n",
    "print(model_path)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train R^2 Score : {grid.best_estimator_.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test R^2 Score : {grid.best_estimator_.score(X_test, y_test):.3f}\")\n",
    "print(f\"Best R^2 Score Through Grid Search : {grid.best_score_:.3f}\")\n",
    "print(f\"Best Parameters : {grid.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
