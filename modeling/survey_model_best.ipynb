{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orencarmeli/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# TODO: add annotations describing usage of different modules\n",
    "\n",
    "from operator import mod\n",
    "from os import getcwd\n",
    "from os.path import exists, join\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from ydata_profiling import ProfileReport\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "# import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import pickle\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "import altair as alt\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set seaborn whitegrid theme\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from random import sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35706, 863)\n",
      "(7741, 863)\n"
     ]
    }
   ],
   "source": [
    "cdc_survey = pd.read_csv('../data/cdc_nhanes_survey_responses_clean.csv')\n",
    "print(cdc_survey.shape)\n",
    "\n",
    "# filter to pregnant moms\n",
    "cdc_survey_pmom = cdc_survey[cdc_survey['has_been_pregnant'] == 1]\n",
    "print(cdc_survey_pmom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depression screener\n",
    "dep_screener_cols = [\n",
    "    'little_interest_in_doing_things',\n",
    "    'feeling_down_depressed_hopeless',\n",
    "    'trouble_falling_or_staying_asleep',\n",
    "    'feeling_tired_or_having_little_energy',\n",
    "    'poor_appetitie_or_overeating',\n",
    "    'feeling_bad_about_yourself',\n",
    "    'trouble_concentrating',\n",
    "    'moving_or_speaking_to_slowly_or_fast',\n",
    "    'thoughts_you_would_be_better_off_dead',\n",
    "    'difficult_doing_daytoday_tasks'\n",
    "]\n",
    "\n",
    "# Alcohol & smoking\n",
    "alcohol_n_smoking_cols = [\n",
    "    'has_smoked_tabacco_last_5days',\n",
    "    'alcoholic_drinks_past_12mo', \n",
    "    'drank_alc',\n",
    "    'alc_drinking_freq',\n",
    "    'alc_per_day',\n",
    "    'times_with_4or5_alc',\n",
    "    'times_with_8plus_alc',\n",
    "    'times_with_12plus_alc',\n",
    "    '4plus_alc_daily',\n",
    "    'days_4plus_drinks_occasion',\n",
    "    'smoked_100_cigs',\n",
    "    'currently_smoke'\n",
    "]\n",
    "\n",
    "#Medical Conditions \n",
    "med_condition_cols = [\n",
    "    'chest_discomfort',\n",
    "    'asthma',\n",
    "    'anemia_treatment',\n",
    "    'blood_transfusion',\n",
    "    'arthritis',\n",
    "    'heart_failure',\n",
    "    'coronary_heart_disease',\n",
    "    'angina_pectoris',\n",
    "    'heart_attack',\n",
    "    'stroke',\n",
    "    'thyroid_issues',\n",
    "    'respiratory_issues',\n",
    "    'abdominal_pain',\n",
    "    'gallstones',\n",
    "    'gallbladder_surgery',\n",
    "    'cancer',\n",
    "    'dr_recommend_lose_weight',\n",
    "    'dr_recommend_exercise',\n",
    "    'dr_recommend_reduce_salt',\n",
    "    'dr_recommend_reduce_fat',\n",
    "    'currently_losing_weight',\n",
    "    'currently_increase_exercise',\n",
    "    'currently_reducing_salt',\n",
    "    'currently_reducing_fat',\n",
    "    'metal_objects',\n",
    "    'has_diabetes',    \n",
    "    #Blood Pressure & Cholesterol \n",
    "    'high_bp',\n",
    "    'age_hypertension',\n",
    "    'hypertension_prescription',\n",
    "    'high_bp_prescription',\n",
    "    'high_cholesterol',\n",
    "    'cholesterol_prescription',\n",
    "    # general health\n",
    "    'has_overweight_diagnosis',   \n",
    "    'height_in',\n",
    "    'weight_lbs', \n",
    "    'general_health_condition',      \n",
    "]\n",
    "\n",
    "# diet, nutrition, & exercise \n",
    "lifestyle_cols = [\n",
    "    # exercise/weight loss\n",
    "    'vigorous_work',\n",
    "    'walk_or_bicycle',\n",
    "    'vigorous_recreation',\n",
    "    'moderate_recreation',    \n",
    "    'count_days_moderate_recreational_activity',   \n",
    "    'count_minutes_moderate_recreational_activity',\n",
    "    'count_minutes_moderate_sedentary_activity',    \n",
    "    'count_lost_10plus_pounds',\n",
    "    'has_tried_to_lose_weight_12mo', \n",
    "    'attempt_weight_loss_1yr',           \n",
    "    # diet\n",
    "    'how_healthy_is_your_diet',    \n",
    "    'milk_consumption_freq',\n",
    "    'govmnt_meal_delivery',\n",
    "    'nonhomemade_meals',\n",
    "    'fastfood_meals',\n",
    "    'readytoeat_meals',\n",
    "    'frozen_pizza'   \n",
    "]\n",
    "\n",
    "# Reproductive Health \n",
    "reproductive_health_cols = [\n",
    "    'regular_periods',\n",
    "    'age_last_period',\n",
    "    'try_pregnancy_1yr',\n",
    "    'see_dr_fertility',\n",
    "    'pelvic_infection',\n",
    "    'pregnant_now',\n",
    "    'pregnancy_count',\n",
    "    'diabetes_pregnancy',\n",
    "    'delivery_count',\n",
    "    'live_birth_count',\n",
    "    'age_at_first_birth',\n",
    "    'age_at_last_birth',\n",
    "    'months_since_birth',\n",
    "    'horomones_not_bc'\n",
    "]\n",
    "\n",
    "# hospital usage & access to care\n",
    "hospital_utilization_n_access_cols = [\n",
    "    'general_health',\n",
    "    'regular_healthcare_place',\n",
    "    'time_since_last_healthcare',\n",
    "    'overnight_in_hospital',\n",
    "    'seen_mental_health_professional',\n",
    "    'count_days_seen_doctor_12mo',\n",
    "    'duration_last_healthcare_visit',   \n",
    "    'have_health_insurance',\n",
    "    'have_private_insurance',\n",
    "    'has_health_insurance_gap',       \n",
    "    'plan_cover_prescriptions'    \n",
    "]\n",
    "\n",
    "# socioeconomic status\n",
    "socioeconomic_cols = [\n",
    "    #Food Security\n",
    "    'emergency_food_received',\n",
    "    'food_stamps_used',      \n",
    "    #Income\n",
    "    'family_poverty_level',\n",
    "    'family_poverty_level_category',\n",
    "    #Occupation\n",
    "    'hours_worked',\n",
    "    'over_35_hrs_worked',\n",
    "    'work_schedule'    \n",
    "]\n",
    "\n",
    "demographic_cols = [\n",
    "    'food_security_level_household',   \n",
    "    'food_security_level_adult',    \n",
    "    'monthly_poverty_index_category',\n",
    "    'monthly_poverty_index',\n",
    "    'count_hours_worked_last_week',\n",
    "    'age_in_years',   \n",
    "    'education_level',\n",
    "    'is_usa_born'\n",
    "]\n",
    "\n",
    "# combine all candidate features\n",
    "candidate_features = dep_screener_cols + \\\n",
    "    alcohol_n_smoking_cols + \\\n",
    "    med_condition_cols + \\\n",
    "    hospital_utilization_n_access_cols + \\\n",
    "    lifestyle_cols + \\\n",
    "    socioeconomic_cols + \\\n",
    "    reproductive_health_cols + \\\n",
    "    demographic_cols\n",
    "\n",
    "\n",
    "len(candidate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(original_df, \n",
    "                   columns, \n",
    "                   test_size_to_use=0.2,\n",
    "                   drop_null_rows=False,\n",
    "                   null_imputer_strategy='median', # mean, median, most_frequent\n",
    "                   use_value_scaler=True,\n",
    "                   use_smote=False,\n",
    "                   return_indices=False):\n",
    "    \"\"\"\n",
    "    Function to build feature & indicator matrices for both train & test.\n",
    "    \"\"\"\n",
    "    \n",
    "    # add target column (MDD)\n",
    "    cols_to_use = columns.copy()\n",
    "    cols_to_use.insert(0, 'MDD')\n",
    "    #cols_to_use.insert(0, 'SEQN')\n",
    "    \n",
    "    df_to_use = original_df[cols_to_use]\n",
    "    \n",
    "    if drop_null_rows:\n",
    "        df_to_use.dropna(inplace=True)\n",
    "    \n",
    "    # Create test & train data\n",
    "    x = df_to_use.iloc[:,1:].values\n",
    "    y = df_to_use['MDD'].values\n",
    "    indices = np.arange(y.shape[0])\n",
    "    \n",
    "    if not drop_null_rows:\n",
    "        # SimpleImputer() = fill in missing values\n",
    "        # note imputer may drop columns if no values exist for it\n",
    "        imputer = SimpleImputer(strategy=null_imputer_strategy)  \n",
    "        x = imputer.fit_transform(x)\n",
    "\n",
    "    # RobustScaler() = scale features to remove outliers\n",
    "    if use_value_scaler:\n",
    "        trans = RobustScaler()\n",
    "        x = trans.fit_transform(x)\n",
    "\n",
    "    x_train, x_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "        x, \n",
    "        y, \n",
    "        indices,\n",
    "        test_size=test_size_to_use, \n",
    "        random_state=42\n",
    "    ) \n",
    "    \n",
    "    # Technique to de-risk from positive class imbalance\n",
    "    if use_smote:\n",
    "        sm = SMOTE(random_state=42)\n",
    "        x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "    \n",
    "    if return_indices:\n",
    "        return x_train, x_test, y_train, y_test, idx_train, idx_test\n",
    "    else:\n",
    "        return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ###############################################################################\n",
    "## function to create test & train dataset\n",
    "\n",
    "def get_model_data(original_df, \n",
    "                   columns, \n",
    "                   test_size_to_use=0.2,\n",
    "                   drop_null_rows=False,\n",
    "                   null_imputer_strategy='median', # mean, median, most_frequent\n",
    "                   use_value_scaler=True,\n",
    "                   use_smote=False,\n",
    "                   return_indices=False):\n",
    "    \"\"\"\n",
    "    Function to build feature & indicator matrices for both train & test.\n",
    "    \"\"\"\n",
    "    \n",
    "    # add target column (MDD)\n",
    "    cols_to_use = columns.copy()\n",
    "    cols_to_use.insert(0, 'MDD')\n",
    "    #cols_to_use.insert(0, 'SEQN')\n",
    "    \n",
    "    df_to_use = original_df[cols_to_use]\n",
    "    \n",
    "    if drop_null_rows:\n",
    "        df_to_use.dropna(inplace=True)\n",
    "    \n",
    "    # Create test & train data\n",
    "    x = df_to_use.iloc[:,1:].values\n",
    "    y = df_to_use['MDD'].values\n",
    "    indices = np.arange(y.shape[0])\n",
    "    \n",
    "    if not drop_null_rows:\n",
    "        # SimpleImputer() = fill in missing values\n",
    "        # note imputer may drop columns if no values exist for it\n",
    "        imputer = SimpleImputer(strategy=null_imputer_strategy)  \n",
    "        x = imputer.fit_transform(x)\n",
    "\n",
    "    # RobustScaler() = scale features to remove outliers\n",
    "    if use_value_scaler:\n",
    "        trans = RobustScaler()\n",
    "        x = trans.fit_transform(x)\n",
    "\n",
    "    x_train, x_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "        x, \n",
    "        y, \n",
    "        indices,\n",
    "        test_size=test_size_to_use, \n",
    "        random_state=42\n",
    "    ) \n",
    "    \n",
    "    # Technique to de-risk from positive class imbalance\n",
    "    if use_smote:\n",
    "        sm = SMOTE(random_state=42)\n",
    "        x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "    \n",
    "    if return_indices:\n",
    "        return x_train, x_test, y_train, y_test, idx_train, idx_test\n",
    "    else:\n",
    "        return x_train, x_test, y_train, y_test\n",
    "\n",
    "## ###############################################################################\n",
    "## Function to get performance across different models\n",
    "\n",
    "def get_performance_df(label_actual, label_pred, model_name):\n",
    "    \"\"\"\n",
    "    Function to calculate performance metrics for model.\n",
    "    Includes precision, recal, F1, & support.\n",
    "    \"\"\"\n",
    "    # create classification report\n",
    "    result_table = classification_report(label_actual, label_pred, output_dict=True)\n",
    "    result_table = pd.DataFrame.from_dict(result_table)\n",
    "\n",
    "    # store for later\n",
    "    accuracies = result_table['accuracy'][0]\n",
    "    \n",
    "    column_key = {\n",
    "        '0':'Depressed (No)',\n",
    "         '1':'Depressed (Yes)',\n",
    "         'accuracy':'accuracy',\n",
    "         'macro avg':'Macro Avg',\n",
    "         'weighted avg':'Weighted Avg'\n",
    "    }\n",
    "\n",
    "    # rename grouping\n",
    "    result_table.columns = [column_key.get(key) for key in result_table.columns]\n",
    "\n",
    "    # create dataframe with 1 row per grouping\n",
    "    result_table.drop(labels = 'accuracy', axis = 1, inplace=True)\n",
    "    result_table = result_table.transpose()\n",
    "    result_table['accuracy'] = [accuracies for i in range(result_table.shape[0])]\n",
    "    result_table = result_table.reset_index()\n",
    "    result_table.rename(columns = {'index':'grouping'},inplace=True)\n",
    "    result_table['model'] = model_name\n",
    "    result_table = result_table[['model','grouping','precision','recall','f1-score','support','accuracy']]\n",
    "    return result_table\n",
    "\n",
    "def generate_models(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    x_test, \n",
    "    y_test):\n",
    "    \"\"\"\n",
    "    Function that trains and makes predictions using 5 of the classifiers went over during the class.\n",
    "    Meant as a helper function for easier testing of different modeling pipelines.\n",
    "    \"\"\"\n",
    "\n",
    "    # K-Nearest Neighbors\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(x_train, y_train)\n",
    "    # test\n",
    "    pred_labels_knn  = knn.predict(x_test)\n",
    "    score_knn = get_performance_df(y_test, pred_labels_knn,'Knn')\n",
    "    # train\n",
    "    pred_labels_knn_train  = knn.predict(x_train)\n",
    "    score_knn_train = get_performance_df(y_train, pred_labels_knn_train,'Knn')\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lm = LogisticRegression()\n",
    "    lm.fit(x_train, y_train)\n",
    "    # test \n",
    "    pred_labels_lr  = lm.predict(x_test)\n",
    "    score_lr = get_performance_df(y_test, pred_labels_lr,'Logistic Regression')\n",
    "    # train \n",
    "    pred_labels_lr_train  = lm.predict(x_train)\n",
    "    score_lr_train = get_performance_df(y_train, pred_labels_lr_train,'Logistic Regression')    \n",
    "        \n",
    "    # Bernoulii Naive Bayes\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(x_train, y_train)\n",
    "    # test \n",
    "    pred_labels_bnb  = bnb.predict(x_test)\n",
    "    score_bnb = get_performance_df(y_test, pred_labels_bnb,'Bernoulli Naive Bayes')    \n",
    "    # train \n",
    "    pred_labels_bnb_train  = bnb.predict(x_train)\n",
    "    score_bnb_train = get_performance_df(y_train, pred_labels_bnb_train,'Bernoulli Naive Bayes')       \n",
    "        \n",
    "    # Gaussian Naive Bayes\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    # test \n",
    "    pred_labels_gnb  = gnb.predict(x_test)\n",
    "    score_gnb = get_performance_df(y_test, pred_labels_gnb,'Gaussian Naive Bayes')  \n",
    "    # train \n",
    "    pred_labels_gnb_train  = gnb.predict(x_train)\n",
    "    score_gnb_train = get_performance_df(y_train, pred_labels_gnb_train,'Gaussian Naive Bayes')         \n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(random_state=0)\n",
    "    rf.fit(x_train, y_train)\n",
    "    # test     \n",
    "    pred_labels_rf  = rf.predict(x_test)\n",
    "    score_rf = get_performance_df(y_test, pred_labels_rf,'Random Forest')   \n",
    "    # train \n",
    "    pred_labels_rf_train  = rf.predict(x_train)\n",
    "    score_rf_train = get_performance_df(y_train, pred_labels_rf_train,'Random Forest')         \n",
    "    \n",
    "    #Decision Tree\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(x_train, y_train)\n",
    "    # test\n",
    "    pred_labels_dt = dt.predict(x_test)\n",
    "    score_dt = get_performance_df(y_test, pred_labels_dt,'Decision Tree')\n",
    "    # train \n",
    "    pred_labels_dt_train  = dt.predict(x_train)\n",
    "    score_dt_train = get_performance_df(y_train, pred_labels_dt_train,'Decision Tree')          \n",
    "\n",
    "    #Gradient Boosting Classifier\n",
    "    gb = GradientBoostingClassifier()\n",
    "    gb.fit(x_train, y_train)\n",
    "    # test \n",
    "    pred_labels_gb = gb.predict(x_test)\n",
    "    score_gb = get_performance_df(y_test, pred_labels_gb,'Gradient Boosting Classifier')\n",
    "    # train \n",
    "    pred_labels_gb_train  = gb.predict(x_train)\n",
    "    score_gb_train = get_performance_df(y_train, pred_labels_gb_train,'Gradient Boosting Classifier')     \n",
    "    \n",
    "    # make dataframe with scores (on test data)\n",
    "    scores_test = pd.concat(\n",
    "        [score_knn, \n",
    "         score_lr, \n",
    "         score_bnb, \n",
    "         score_gnb, \n",
    "         score_rf, \n",
    "         score_dt, \n",
    "         score_gb]\n",
    "    )\n",
    "    scores_test = scores_test.sort_values(by = 'recall', ascending=False)\n",
    "    \n",
    "    # make dataframe with scores (on train data)\n",
    "    scores_train = pd.concat(\n",
    "        [score_knn_train, \n",
    "         score_lr_train, \n",
    "         score_bnb_train, \n",
    "         score_gnb_train, \n",
    "         score_rf_train, \n",
    "         score_dt_train, \n",
    "         score_gb_train]\n",
    "    )\n",
    "    scores_train = scores_train.sort_values(by = 'recall', ascending=False)    \n",
    "        \n",
    "    # make dataframe with predictions\n",
    "    predictions = pd.DataFrame({\n",
    "        'actuals':y_test,\n",
    "        'pred_knn':pred_labels_knn,\n",
    "        'pred_logistic_regression':pred_labels_lr,\n",
    "        'pred_bernoulli_naive_bayes':pred_labels_bnb,\n",
    "        'pred_gaussian_naive_bayes':pred_labels_gnb,\n",
    "        'pred_random_forest':pred_labels_rf,\n",
    "        'pred_decision_tree':pred_labels_dt,\n",
    "        'pred_gradient_boosting_classifier':pred_labels_gb\n",
    "    })\n",
    "\n",
    "    return scores_test, predictions, scores_train\n",
    "\n",
    "## ###############################################################################\n",
    "## Functions for Error analysis\n",
    "\n",
    "def plot_confusion_matrix(y_test, pred_labels):\n",
    "    \"\"\"\n",
    "    Function that displays a confusion matrix for provided true and predicted classes\n",
    "    \"\"\"\n",
    "    #print(f'cover type 1 and type 2 total correct {np.sum(np.diag(metrics.confusion_matrix(y_test, pred_labels))[:2])}')\n",
    "\n",
    "    cm = confusion_matrix(y_test, pred_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    disp = disp.plot(include_values=True, cmap='viridis', ax=ax, xticks_rotation='horizontal')    \n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def label_pred(row):\n",
    "    \"\"\"\n",
    "    Function that labels prediction cases into TP, TN, FP, FN\n",
    "    \"\"\"\n",
    "    if row['y_actual'] == row['y_pred']:\n",
    "        if row['y_actual'] == 1:\n",
    "            result = 'TP'\n",
    "        else:\n",
    "            result = 'TN'\n",
    "    else: \n",
    "        if row['y_actual'] == 1:\n",
    "            result = 'FN'\n",
    "        else:\n",
    "            result = 'FP'\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_error_data(\n",
    "    y_actuals, \n",
    "    y_predictions,\n",
    "    x_test_matrix,\n",
    "    x_test_columns):\n",
    "    \"\"\"\n",
    "    Function that creates a clean dataset to perform error analysis on test observations.\n",
    "    \"\"\"    \n",
    "    \n",
    "    # create dataframe with actuals & predictions w/ labels\n",
    "    prediction_labels = pd.DataFrame(columns = ['y_actual','y_pred'])\n",
    "    prediction_labels['y_actual'] = y_actuals\n",
    "    prediction_labels['y_pred'] = y_predictions\n",
    "    prediction_labels['label'] = prediction_labels.apply(label_pred, axis = 1)\n",
    "\n",
    "    # feature df \n",
    "    feature_df = pd.DataFrame(x_test_matrix, columns = x_test_columns)\n",
    "\n",
    "    # combine into 1\n",
    "    pred_data = pd.concat([prediction_labels, feature_df], axis = 1)\n",
    "    \n",
    "    return pred_data\n",
    "\n",
    "def create_error_plots(\n",
    "    prediction_data,\n",
    "    columns_to_plot,\n",
    "    show_bar_plot=True,\n",
    "    show_density_plot=False):\n",
    "    \"\"\"\n",
    "    Function that creates bi-variate plots comparing TP, TN, FP, FN for each desired feature column.\n",
    "    \"\"\"\n",
    "\n",
    "    ### Bi-variate plots\n",
    "    for column in columns_to_plot:\n",
    "    \n",
    "        if show_density_plot:\n",
    "            ## Density plot\n",
    "            sns.kdeplot(\n",
    "                data=prediction_data, \n",
    "                x=column, \n",
    "                hue=\"label\", \n",
    "                cut=0, \n",
    "                common_norm=False, \n",
    "                alpha=0.4\n",
    "            )\n",
    "\n",
    "        if show_bar_plot:\n",
    "            ## barplot\n",
    "            # create % of total column by group\n",
    "            group_data = prediction_data.groupby(['label',column])['y_actual'].count().reset_index()\n",
    "            group_data['Pct of Total'] = group_data['y_actual'] / group_data.groupby('label')['y_actual'].transform('sum')\n",
    "\n",
    "            sns.catplot(\n",
    "                data=group_data, \n",
    "                kind=\"bar\",\n",
    "                x=column, \n",
    "                y=\"Pct of Total\", \n",
    "                hue=\"label\",\n",
    "                alpha = 0.8\n",
    "            )\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_survey_pmom['num_dep_screener_0'] = (cdc_survey_pmom[dep_screener_cols]==0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1 (Include All Observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features_opt1 = dep_screener_cols + ['times_with_12plus_alc',\n",
    " 'seen_mental_health_professional',\n",
    " 'count_days_seen_doctor_12mo',\n",
    " 'count_lost_10plus_pounds',\n",
    " 'arthritis',\n",
    " 'horomones_not_bc',\n",
    " 'is_usa_born',\n",
    " 'times_with_8plus_alc',\n",
    " 'time_since_last_healthcare',\n",
    " 'duration_last_healthcare_visit',\n",
    " 'work_schedule',\n",
    " 'age_in_years',\n",
    " 'regular_periods',\n",
    " 'count_minutes_moderate_sedentary_activity',\n",
    " 'emergency_food_received',\n",
    " 'high_bp',\n",
    " 'dr_recommend_exercise',\n",
    " 'metal_objects',\n",
    " 'drank_alc',\n",
    " 'cholesterol_prescription',\n",
    " 'smoked_100_cigs',\n",
    " 'vigorous_recreation',\n",
    " 'dr_recommend_lose_weight',\n",
    " 'cancer',\n",
    " 'chest_discomfort',\n",
    " 'have_health_insurance',\n",
    " 'weight_lbs',\n",
    " 'high_cholesterol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6192, 38)\n",
      "(1549, 38)\n",
      "(6192,)\n",
      "(1549,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, idx_train, idx_test = get_model_data(\n",
    "    original_df = cdc_survey_pmom,\n",
    "    columns = model_features_opt1,\n",
    "    return_indices = True\n",
    ")\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>grouping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Depressed (No)</td>\n",
       "      <td>0.951777</td>\n",
       "      <td>0.809353</td>\n",
       "      <td>0.874806</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>0.792124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Depressed (Yes)</td>\n",
       "      <td>0.277929</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.387833</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.792124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.614853</td>\n",
       "      <td>0.725431</td>\n",
       "      <td>0.631319</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>0.792124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.882608</td>\n",
       "      <td>0.792124</td>\n",
       "      <td>0.824819</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>0.792124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model         grouping  precision    recall  f1-score  \\\n",
       "0  Gaussian Naive Bayes   Depressed (No)   0.951777  0.809353  0.874806   \n",
       "1  Gaussian Naive Bayes  Depressed (Yes)   0.277929  0.641509  0.387833   \n",
       "2  Gaussian Naive Bayes        Macro Avg   0.614853  0.725431  0.631319   \n",
       "3  Gaussian Naive Bayes     Weighted Avg   0.882608  0.792124  0.824819   \n",
       "\n",
       "   support  accuracy  \n",
       "0   1390.0  0.792124  \n",
       "1    159.0  0.792124  \n",
       "2   1549.0  0.792124  \n",
       "3   1549.0  0.792124  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "pred_labels_gnb  = gnb.predict(x_test)\n",
    "score_gnb = get_performance_df(y_test, pred_labels_gnb,'Gaussian Naive Bayes')  \n",
    "score_gnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on those with 1+ dep screener answered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = pd.DataFrame(gnb_final.predict_proba(x_test))\n",
    "pred_prob.columns = ['depressed_no_prob','depressed_yes_prob']\n",
    "pred_prob['y_pred'] = pred_labels_gnb\n",
    "pred_prob['y_actual'] = y_test\n",
    "\n",
    "pred_prob_with_features = pd.concat([\n",
    "    pred_prob, \n",
    "    # column bind test observations with their original values\n",
    "    cdc_survey_pmom.iloc[idx_test][model_features_opt1].reset_index()\n",
    "], axis=1)\n",
    "\n",
    "pred_prob_with_features['num_dep_screener_0'] = (pred_prob_with_features[dep_screener_cols]==0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>grouping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GNB: Only those with 1 dep screener replied</td>\n",
       "      <td>Depressed (No)</td>\n",
       "      <td>0.929104</td>\n",
       "      <td>0.675712</td>\n",
       "      <td>0.782404</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.680139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GNB: Only those with 1 dep screener replied</td>\n",
       "      <td>Depressed (Yes)</td>\n",
       "      <td>0.275758</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>0.396514</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.680139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GNB: Only those with 1 dep screener replied</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.602431</td>\n",
       "      <td>0.690569</td>\n",
       "      <td>0.589459</td>\n",
       "      <td>866.0</td>\n",
       "      <td>0.680139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GNB: Only those with 1 dep screener replied</td>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.831781</td>\n",
       "      <td>0.680139</td>\n",
       "      <td>0.724921</td>\n",
       "      <td>866.0</td>\n",
       "      <td>0.680139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         model         grouping  precision  \\\n",
       "0  GNB: Only those with 1 dep screener replied   Depressed (No)   0.929104   \n",
       "1  GNB: Only those with 1 dep screener replied  Depressed (Yes)   0.275758   \n",
       "2  GNB: Only those with 1 dep screener replied        Macro Avg   0.602431   \n",
       "3  GNB: Only those with 1 dep screener replied     Weighted Avg   0.831781   \n",
       "\n",
       "     recall  f1-score  support  accuracy  \n",
       "0  0.675712  0.782404    737.0  0.680139  \n",
       "1  0.705426  0.396514    129.0  0.680139  \n",
       "2  0.690569  0.589459    866.0  0.680139  \n",
       "3  0.680139  0.724921    866.0  0.680139  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_replied_to_dep_screener = pred_prob_with_features[pred_prob_with_features['num_dep_screener_0'] < 9]\n",
    "\n",
    "get_performance_df(\n",
    "    data_replied_to_dep_screener['y_actual'], \n",
    "    data_replied_to_dep_screener['y_pred'],\n",
    "    'GNB: Only those with 1 dep screener replied'\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ensemble Model \n",
    "\n",
    "Build 2 models; \n",
    "- Model 1: trained on the entire dataset\n",
    "- Model 2: trained on observations where the respondent answers 0 for 9+ of the depression screeners\n",
    "\n",
    "\n",
    "Notes\n",
    "- _low = has 9+ dep screeners answered 0\n",
    "- _high = has <9 dep screeners answered 0\n",
    "- https://datascience.stackexchange.com/questions/69934/decision-trees-change-result-at-every-run-how-can-i-trust-of-my-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data_ensemble(original_df, \n",
    "                            columns_to_use):\n",
    "    \"\"\"\n",
    "    Function to build feature & indicator matrices for both train & test.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_low_dep_screener = original_df[original_df['num_dep_screener_0'] >= 9].copy()\n",
    "    data_high_dep_screener = original_df[original_df['num_dep_screener_0'] < 9].copy()\n",
    "    \n",
    "    x_train_low, x_test_low, y_train_low, y_test_low = get_model_data(\n",
    "        original_df = data_low_dep_screener,\n",
    "        columns = columns_to_use\n",
    "    )\n",
    "    \n",
    "    x_train_high, x_test_high, y_train_high, y_test_high = get_model_data(\n",
    "        original_df = data_high_dep_screener,\n",
    "        columns = columns_to_use\n",
    "    )\n",
    "    \n",
    "    return x_train_low, x_test_low, y_train_low, y_test_low, x_train_high, x_test_high, y_train_high, y_test_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2677, 38)\n",
      "(670, 38)\n",
      "(2677,)\n",
      "(670,)\n",
      "(3515, 38)\n",
      "(879, 38)\n",
      "(3515,)\n",
      "(879,)\n"
     ]
    }
   ],
   "source": [
    "x_train_low, x_test_low, y_train_low, y_test_low, x_train_high, x_test_high, y_train_high, y_test_high = get_model_data_ensemble(\n",
    "    original_df = cdc_survey_pmom,\n",
    "    columns_to_use = model_features_opt1\n",
    ")\n",
    "\n",
    "print(x_train_low.shape)\n",
    "print(x_test_low.shape)\n",
    "print(y_train_low.shape)\n",
    "print(y_test_low.shape)\n",
    "print(x_train_high.shape)\n",
    "print(x_test_high.shape)\n",
    "print(y_train_high.shape)\n",
    "print(y_test_high.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grouping</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Depressed (No)</td>\n",
       "      <td>0.822335</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.801162</td>\n",
       "      <td>1379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Depressed (Yes)</td>\n",
       "      <td>0.629412</td>\n",
       "      <td>0.409962</td>\n",
       "      <td>0.303977</td>\n",
       "      <td>0.801162</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.725873</td>\n",
       "      <td>0.645198</td>\n",
       "      <td>0.625673</td>\n",
       "      <td>0.801162</td>\n",
       "      <td>1549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.801162</td>\n",
       "      <td>0.828801</td>\n",
       "      <td>0.876757</td>\n",
       "      <td>0.801162</td>\n",
       "      <td>1549.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          grouping    recall  f1-score  precision  accuracy  support\n",
       "0   Depressed (No)  0.822335  0.880435   0.947368  0.801162   1379.0\n",
       "1  Depressed (Yes)  0.629412  0.409962   0.303977  0.801162    170.0\n",
       "2        Macro Avg  0.725873  0.645198   0.625673  0.801162   1549.0\n",
       "3     Weighted Avg  0.801162  0.828801   0.876757  0.801162   1549.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################# Model 1: Based on all datapoints\n",
    "x_train_all = np.concatenate((x_train_low, x_train_high))\n",
    "y_train_all = np.concatenate((y_train_low, y_train_high))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train_all, y_train_all)\n",
    "\n",
    "################# Model 2: Based on cases where >8 dep screener are 0\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(x_train_low, y_train_low)\n",
    "\n",
    "################# Predict \n",
    "\n",
    "# Model 1: use for high cases\n",
    "y_pred_high = gnb.predict(x_test_high)\n",
    "\n",
    "# Model 2: use for low cases\n",
    "y_pred_low = dt.predict(x_test_low)\n",
    "\n",
    "y_pred = np.concatenate((y_pred_high, y_pred_low))\n",
    "y_actual = np.concatenate((y_test_high, y_test_low))\n",
    "\n",
    "ensemble_performance = get_performance_df(\n",
    "    label_actual = y_actual, \n",
    "    label_pred = y_pred,\n",
    "    model_name = 'GNB + Decision Tree'\n",
    ")\n",
    "ensemble_performance[['grouping','recall','f1-score','precision','accuracy','support']].sort_values(by='grouping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2 (Only Observations with at least 1 dep screener reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features_opt2 = dep_screener_cols + ['seen_mental_health_professional',\n",
    " 'times_with_12plus_alc',\n",
    " 'duration_last_healthcare_visit',\n",
    " 'time_since_last_healthcare',\n",
    " 'cholesterol_prescription',\n",
    " 'high_cholesterol',\n",
    " 'age_in_years',\n",
    " 'horomones_not_bc',\n",
    " 'times_with_8plus_alc',\n",
    " 'months_since_birth',\n",
    " 'arthritis',\n",
    " 'high_bp',\n",
    " 'regular_periods',\n",
    " 'moderate_recreation',\n",
    " 'thyroid_issues',\n",
    " 'vigorous_recreation',\n",
    " 'stroke',\n",
    " 'is_usa_born',\n",
    " 'asthma']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3515, 29)\n",
      "(879, 29)\n",
      "(3515,)\n",
      "(879,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, idx_train, idx_test = get_model_data(\n",
    "    original_df = cdc_survey_pmom[cdc_survey_pmom['num_dep_screener_0'] < 9],\n",
    "    columns = model_features_opt2,\n",
    "    return_indices = True\n",
    ")\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>grouping</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian Naive Bayes (Subset)</td>\n",
       "      <td>Depressed (No)</td>\n",
       "      <td>0.938433</td>\n",
       "      <td>0.680650</td>\n",
       "      <td>0.789020</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.69397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gaussian Naive Bayes (Subset)</td>\n",
       "      <td>Depressed (Yes)</td>\n",
       "      <td>0.311953</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.443064</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.69397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Naive Bayes (Subset)</td>\n",
       "      <td>Macro Avg</td>\n",
       "      <td>0.625193</td>\n",
       "      <td>0.722468</td>\n",
       "      <td>0.616042</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0.69397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaussian Naive Bayes (Subset)</td>\n",
       "      <td>Weighted Avg</td>\n",
       "      <td>0.838652</td>\n",
       "      <td>0.693970</td>\n",
       "      <td>0.733919</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0.69397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model         grouping  precision    recall  \\\n",
       "0  Gaussian Naive Bayes (Subset)   Depressed (No)   0.938433  0.680650   \n",
       "1  Gaussian Naive Bayes (Subset)  Depressed (Yes)   0.311953  0.764286   \n",
       "2  Gaussian Naive Bayes (Subset)        Macro Avg   0.625193  0.722468   \n",
       "3  Gaussian Naive Bayes (Subset)     Weighted Avg   0.838652  0.693970   \n",
       "\n",
       "   f1-score  support  accuracy  \n",
       "0  0.789020    739.0   0.69397  \n",
       "1  0.443064    140.0   0.69397  \n",
       "2  0.616042    879.0   0.69397  \n",
       "3  0.733919    879.0   0.69397  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "pred_labels_gnb  = gnb.predict(x_test)\n",
    "score_gnb = get_performance_df(y_test, pred_labels_gnb,'Gaussian Naive Bayes (Subset)')  \n",
    "score_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['months_since_birth',\n",
       " 'moderate_recreation',\n",
       " 'thyroid_issues',\n",
       " 'stroke',\n",
       " 'asthma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[feature for feature in model_features_opt2 if feature not in model_features_opt1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
