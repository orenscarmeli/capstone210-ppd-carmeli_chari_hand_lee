{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import mod\n",
    "from os import getcwd\n",
    "from os.path import exists, join\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "import random\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import pickle\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cdc_clean = pd.read_csv('../data/cdc_nhanes_survey_responses_clean.csv')\n",
    "# v2 csv\n",
    "df_cdc_clean = pd.read_csv('../data/df_cdc_clean_v2.csv')\n",
    "\n",
    "# filter to moms\n",
    "df_cdc_clean = df_cdc_clean[df_cdc_clean['has_been_pregnant'] == 1]\n",
    "df_cdc_clean = df_cdc_clean.drop(columns=['has_been_pregnant'])\n",
    "\n",
    "df_cdc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_keep = ['SEQN', 'MDD']\n",
    "# # cols_to_keep.extend(df_cdc_clean.columns.tolist()[-38:])\n",
    "# cols_to_keep.extend([col for col in df_cdc_clean.columns.tolist() if '_' in col and '_x' not in col and '_y' not in col])\n",
    "# cols_to_keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    'SEQN',\n",
    "    'MDD',\n",
    "    # 'is_male',\n",
    "    # 'has_been_pregnant',\n",
    "    'age_with_angina_pectoris',\n",
    "    'age_liver_condition',\n",
    "    'age_range_first_menstrual_period',\n",
    "    'annual_healthcare_visit_count',\n",
    "    'have_liver_condition',\n",
    "    'type_of_work_done_last_week',\n",
    "    'weight_change_intentional',\n",
    "    'days_nicotine_substitute_used',\n",
    "    'pain_relief_from_cardio_recoverytime',\n",
    "    # Depression screener\n",
    "    'little_interest_in_doing_things',\n",
    "    'feeling_down_depressed_hopeless',\n",
    "    'trouble_falling_or_staying_asleep',\n",
    "    'feeling_tired_or_having_little_energy',\n",
    "    'poor_appetitie_or_overeating',\n",
    "    'feeling_bad_about_yourself',\n",
    "    'trouble_concentrating',\n",
    "    'moving_or_speaking_to_slowly_or_fast',\n",
    "    'thoughts_you_would_be_better_off_dead',\n",
    "    'difficult_doing_daytoday_tasks',\n",
    "    # Alcohol & smoking\n",
    "    'has_smoked_tabacco_last_5days',\n",
    "    'alcoholic_drinks_past_12mo',    \n",
    "    # Diet & Nutrition\n",
    "    'how_healthy_is_your_diet',    \n",
    "    'count_lost_10plus_pounds',\n",
    "    'has_tried_to_lose_weight_12mo',       \n",
    "    # Physical health & Medical History\n",
    "    'count_days_seen_doctor_12mo',\n",
    "    'duration_last_healthcare_visit',        \n",
    "    'count_days_moderate_recreational_activity',   \n",
    "    'count_minutes_moderate_recreational_activity',\n",
    "    'count_minutes_moderate_sedentary_activity',\n",
    "    'general_health_condition',    \n",
    "    'has_diabetes',\n",
    "    'has_overweight_diagnosis',         \n",
    "    # Demographic data\n",
    "    'food_security_level_household',   \n",
    "    'food_security_level_adult',    \n",
    "    'monthly_poverty_index_category',\n",
    "    'monthly_poverty_index',\n",
    "    'count_hours_worked_last_week',\n",
    "    'age_in_years',   \n",
    "    'education_level',\n",
    "    'is_usa_born',    \n",
    "    'has_health_insurance',\n",
    "    'has_health_insurance_gap'   \n",
    "]\n",
    "len(cols_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdc_clean = df_cdc_clean[cols_to_keep]\n",
    "df_cdc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProfileReport(df_cdc_clean, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQN and MDD are the first two columns in the df, so exclude from X\n",
    "X = df_cdc_clean.iloc[:,2:].values\n",
    "y = df_cdc_clean['MDD'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(pred_labels, y_test, algo_name, show_full_report=False):\n",
    "    eval_on = 'macro avg' \n",
    "    # eval_on = 'depressed' #not_depressed\n",
    "    target_names = ['not_depressed', 'depressed',]\n",
    "    \n",
    "    df_cls_rpt = pd.DataFrame(\n",
    "        classification_report(\n",
    "            y_test, \n",
    "            pred_labels, \n",
    "            target_names=target_names, \n",
    "            output_dict=True\n",
    "        )\n",
    "    ).rename_axis('metric')\\\n",
    "    .reset_index()\n",
    "\n",
    "    \n",
    "    if show_full_report == True:\n",
    "        display(df_cls_rpt)\n",
    "    accuracy = df_cls_rpt[['accuracy']].iloc[0, 0]\n",
    "    df_cls_rpt = df_cls_rpt[['metric', eval_on]].T\n",
    "    df_cls_rpt.columns = df_cls_rpt.iloc[0,:]\n",
    "    df_cls_rpt = df_cls_rpt.iloc[1:,:]\n",
    "    df_cls_rpt['accuracy'] = accuracy\n",
    "\n",
    "    df_cls_rpt['algo'] = algo_name\n",
    "\n",
    "    first_column = df_cls_rpt.pop('algo')\n",
    "    df_cls_rpt.insert(0, 'algo', first_column)\n",
    "\n",
    "    # display(df_cls_rpt)\n",
    "    return df_cls_rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, pred_labels):\n",
    "    \"\"\"\n",
    "    Function that displays a confusion matrix for provided true and predicted classes\n",
    "    \"\"\"\n",
    "    #print(f'cover type 1 and type 2 total correct {np.sum(np.diag(metrics.confusion_matrix(y_test, pred_labels))[:2])}')\n",
    "\n",
    "    cm = confusion_matrix(y_test, pred_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    disp = disp.plot(include_values=True, cmap='viridis', ax=ax, xticks_rotation='horizontal')    \n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_grid_search_pred(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test,\n",
    "    y_test,\n",
    "    algo,\n",
    "    algo_name,\n",
    "    params,\n",
    "    cv,\n",
    "    verbose,\n",
    "    imputer,\n",
    "    scaler):\n",
    "    score_on = 'recall' #'f1_score'\n",
    "\n",
    "    pipeline_list = [imputer, scaler, algo]\n",
    "    # drop imputer or scaler if none\n",
    "    pipeline_list = [step for step in pipeline_list if step is not None]\n",
    "\n",
    "    processing_pipeline = make_pipeline(imputer, scaler, algo)\n",
    "    processing_pipeline = make_pipeline()\n",
    "    i = 1\n",
    "    for step in pipeline_list:\n",
    "        processing_pipeline.steps.append([(type(step).__name__).lower(), step])\n",
    "        i += 1\n",
    "    grid = GridSearchCV(\n",
    "        processing_pipeline, \n",
    "        param_grid=params, \n",
    "        n_jobs=-1, \n",
    "        cv=cv, \n",
    "        verbose=verbose, \n",
    "        scoring='recall')\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    pred_labels = [x.round() for x in grid.best_estimator_.predict(X_test)]\n",
    "    pred_labels = [x.round() for x in pred_labels]\n",
    "\n",
    "    df_algo_cls_rpt = get_classification_report(pred_labels, y_test, algo_name)\n",
    "    df_algo_cls_rpt['train_r2'] = grid.best_estimator_.score(X_train, y_train)\n",
    "    df_algo_cls_rpt['test_r2'] = grid.best_estimator_.score(X_test, y_test)\n",
    "    df_algo_cls_rpt['best_params'] = str(grid.best_params_)\n",
    "    tn, fp, fn, tp = confusion_matrix(pred_labels, y_test).ravel()\n",
    "    df_algo_cls_rpt['tp'] = tp\n",
    "    df_algo_cls_rpt['fn'] = fn\n",
    "    df_algo_cls_rpt['fp'] = fp\n",
    "    df_algo_cls_rpt['tn'] = tn\n",
    "\n",
    "    \n",
    "    return df_algo_cls_rpt, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_baseline_pred(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test,\n",
    "    y_test,\n",
    "    show_full_report,\n",
    "    algo,\n",
    "    algo_name,\n",
    "    imputer,\n",
    "    scaler):\n",
    "\n",
    "    pipeline_list = [imputer, scaler, algo]\n",
    "    # drop imputer or scaler if none\n",
    "    pipeline_list = [step for step in pipeline_list if step is not None]\n",
    "    \n",
    "    try:\n",
    "        processing_pipeline = make_pipeline()\n",
    "        i = 1\n",
    "        for step in pipeline_list:\n",
    "            processing_pipeline.steps.append([(type(step).__name__).lower(), step])\n",
    "            i += 1\n",
    "\n",
    "        processing_pipeline.fit(X_train, y_train)\n",
    "        pred_labels  = processing_pipeline.predict(X_test)\n",
    "        pred_labels = [x.round() for x in pred_labels]\n",
    "\n",
    "        df_algo_cls_rpt = get_classification_report(pred_labels, y_test, algo_name, show_full_report)\n",
    "        tn, fp, fn, tp = confusion_matrix(pred_labels, y_test).ravel()\n",
    "        df_algo_cls_rpt['tp'] = tp\n",
    "        df_algo_cls_rpt['fn'] = fn\n",
    "        df_algo_cls_rpt['fp'] = fp\n",
    "        df_algo_cls_rpt['tn'] = tn\n",
    "        \n",
    "        return df_algo_cls_rpt, pred_labels\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        raise Exception (f'{algo_name} might not work with NaN')\n",
    "        \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def baseline_models(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test, \n",
    "    y_test,\n",
    "    algo_attempt_list,\n",
    "    do_smote=False,\n",
    "    show_confusion_matrix=False,\n",
    "    show_full_report=False,\n",
    "    grid_search=False,\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    imputer=SimpleImputer(),\n",
    "    scaler=RobustScaler()\n",
    "    ):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # do_smote\n",
    "    if do_smote == True:\n",
    "        # have to impute first because smote won't take nulls\n",
    "        my_imputer = SimpleImputer()\n",
    "        X_train = my_imputer.fit_transform(X_train)\n",
    "        X_test = my_imputer.fit_transform(X_test)\n",
    "\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "    df_cls_rpt = pd.DataFrame()\n",
    "    conf_mtrx_dict = {}\n",
    "\n",
    "    if algo_attempt_list == 'all':\n",
    "        algo_attempt_list = ['knn', 'lm', 'bnb', 'gnb', 'dt', 'rf', 'gb', 'xgb']\n",
    "    \n",
    "    for a in algo_attempt_list:\n",
    "        # SVR\n",
    "        if a == 'svr':\n",
    "            algo_name = 'SVR'\n",
    "            params = {\n",
    "                \"simpleimputer__strategy\": [\"mean\", \"median\"],\n",
    "                \"robustscaler__quantile_range\": [(25.0, 75.0), (30.0, 70.0)],\n",
    "                \"svr__C\": [0.1, 1.0],\n",
    "                \"svr__gamma\": [\"auto\", 0.1],\n",
    "            }\n",
    "            algo = SVR()\n",
    "        elif a == 'knn':\n",
    "            algo_name = 'KNN'\n",
    "            params = {\n",
    "                'kneighborsclassifier__n_neighbors': list(range(1, 15))\n",
    "            }\n",
    "            print(params)\n",
    "            algo = KNeighborsClassifier()\n",
    "        elif a == 'lm':\n",
    "            algo_name = 'Logistic Regression'\n",
    "            params = {\n",
    "                'logisticregression__penalty': ['l1','l2'], \n",
    "                'logisticregression__C': [0.001,0.01,0.1,1,10,100,1000]\n",
    "            }\n",
    "            algo = LogisticRegression(max_iter=1000, penalty='l2', C=10)\n",
    "        elif a == 'bnb':\n",
    "            algo_name = 'Bernoulli Naive Bayes'\n",
    "            params = {\n",
    "                'bernoullinb__alpha': np.logspace(0,-9, num=100),\n",
    "                'bernoullinb__binarize': [0.0, 1.0, 2.0],\n",
    "                # 'bernoullinb__fit_prior': [True, False]\n",
    "            }\n",
    "            algo = BernoulliNB()\n",
    "        elif a == 'gnb':\n",
    "            algo_name = 'Gaussian Naive Bayes'\n",
    "            params = {\n",
    "                'gaussiannb__var_smoothing': np.logspace(0,-9, num=100)\n",
    "            }\n",
    "            algo = GaussianNB()\n",
    "        elif a == 'dt':\n",
    "            algo_name = 'Decision Tree'\n",
    "            params = {\n",
    "                'decisiontreeclassifier__criterion':['gini', 'entropy', 'logloss'],\n",
    "                'decisiontreeclassifier__max_depth': np.arange(1, 15)\n",
    "            }\n",
    "            algo = DecisionTreeClassifier(random_state=42)\n",
    "        elif a == 'rf':\n",
    "            algo_name = 'Random Forest'\n",
    "            params = {\n",
    "                'randomforestclassifier__criterion': ['gini', 'entropy', 'logloss'],\n",
    "                \"randomforestclassifier__n_estimators\": [10, 20, 40, 80, 100, 125, 150],\n",
    "                \"randomforestclassifier__max_features\": [\"sqrt\", \"log2\", None],\n",
    "                \"randomforestclassifier__min_samples_split\": [1, 2, 4, 8],\n",
    "                \"randomforestclassifier__bootstrap\": [True, False],\n",
    "            }\n",
    "            algo = RandomForestClassifier(random_state=42)\n",
    "        elif a == 'gb':\n",
    "            algo_name = 'Gradient Boosting Classifier'\n",
    "            params = {\n",
    "                \"gradientboostingclassifier__loss\":[\"log_loss\", \"exponential\"],\n",
    "                \"gradientboostingclassifier__learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "                # \"gradientboostingclassifier__min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "                # \"gradientboostingclassifier__min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "                \"gradientboostingclassifier__max_depth\":[3,5,8],\n",
    "                \"gradientboostingclassifier__max_features\":[\"log2\", \"sqrt\"],\n",
    "                \"gradientboostingclassifier__criterion\": [\"friedman_mse\", \"mae\"],\n",
    "                # \"gradientboostingclassifier__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "                \"gradientboostingclassifier__n_estimators\":[10, 25, 50, 100, 125, 150]\n",
    "            }\n",
    "            algo = GradientBoostingClassifier()\n",
    "        elif a == 'xgb':\n",
    "            algo_name = 'XGBoost'\n",
    "            params = {\n",
    "                'xgbclassifier__max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "                'xgbclassifier__learning_rate': [0.001, 0.01, 0.1, 0.20, 0.25, 0.30],\n",
    "                \"xgbclassifier__gamma\":[0, 0.25, 0.5, 0.75,1],\n",
    "                'xgbclassifier__n_estimators': [100, 500, 1000],\n",
    "            }\n",
    "            algo = xgb.XGBClassifier()\n",
    "        else:\n",
    "            raise Exception(f'{a} is not a supported algorithm')\n",
    "            # print(f'{a} is not a supported algorithm')\n",
    "\n",
    "        if grid_search == True and params is not None:\n",
    "            df_algo_cls_rpt, pred_labels = algo_grid_search_pred(\n",
    "                X_train, \n",
    "                y_train, \n",
    "                X_test,\n",
    "                y_test,\n",
    "                algo=algo,\n",
    "                algo_name=algo_name,\n",
    "                params=params,\n",
    "                imputer=imputer,\n",
    "                scaler=scaler,\n",
    "                cv=cv,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            if grid_search == True and params is None:\n",
    "                # print(f'Params not defined for {algo_name} GridSearch. Fitting baseline model.')\n",
    "                pass\n",
    "            df_algo_cls_rpt, pred_labels = algo_baseline_pred(\n",
    "                X_train, \n",
    "                y_train, \n",
    "                X_test,\n",
    "                y_test,\n",
    "                show_full_report,\n",
    "                algo=algo,\n",
    "                algo_name=algo_name,\n",
    "                imputer=imputer,\n",
    "                scaler=scaler,\n",
    "            )\n",
    "\n",
    "        df_cls_rpt = pd.concat([\n",
    "                df_algo_cls_rpt, \n",
    "                df_cls_rpt], \n",
    "                ignore_index=True\n",
    "        )\n",
    "        conf_mtrx_dict[algo_name] = pred_labels\n",
    "    \n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        for k,v in conf_mtrx_dict.items():\n",
    "            print(f'{k} Confusion Matrix')\n",
    "            plot_confusion_matrix(y_test, v)\n",
    "\n",
    "    df_cls_rpt.sort_values(by=['f1-score'], ascending=False, inplace=True)\n",
    "    df_cls_rpt = df_cls_rpt.reset_index(drop=True)\n",
    "    return df_cls_rpt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_models(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    algo_attempt_list=['bnb',],\n",
    "    grid_search=True,\n",
    "    cv=3,\n",
    "    verbose=0,\n",
    "    imputer=SimpleImputer()\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force \n",
    "Can select different algo, imputer, scaler, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# ##### with all setting each trial takes a while ##########\n",
    "# ##### commenting out options can make bring iteration time down drastically ###########\n",
    "# num_trials = 2\n",
    "# best_score = 0\n",
    "# primary_eval_metric = 'recall'\n",
    "# secondary_eval_metric = 'f1-score'\n",
    "# best_cols = []\n",
    "# df_best_scores = pd.DataFrame()\n",
    "\n",
    "# try:\n",
    "    \n",
    "#     for i in tqdm(range(1, num_trials+1)):\n",
    "#         df_random_feats = df_cdc_clean.iloc[:,2:]\n",
    "#         rand_num_features = random.randint(3, (df_random_feats.shape[1]))\n",
    "#         df_random_feats = df_random_feats.sample(n=rand_num_features, axis='columns')\n",
    "#         X = df_random_feats\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(\n",
    "#             X, y, test_size=0.2, random_state=42\n",
    "#         )\n",
    "\n",
    "#         # SMOTE or not\n",
    "#         for b in [True, False]:\n",
    "#             # different imputers\n",
    "#             for imp in [KNNImputer(), SimpleImputer(strategy='mean'), SimpleImputer(strategy='most_frequent')]:\n",
    "#                 for scl in [RobustScaler(), StandardScaler(), MinMaxScaler(), Normalizer()]:\n",
    "#                     df_scores = baseline_models(\n",
    "#                         X_train, \n",
    "#                         y_train, \n",
    "#                         X_test, \n",
    "#                         y_test, \n",
    "#                         do_smote=b, \n",
    "#                         algo_attempt_list=['bnb', 'gnb', 'lm'],\n",
    "#                         grid_search=True,\n",
    "#                         cv=5,\n",
    "#                         verbose=0,\n",
    "#                         imputer=imp,\n",
    "#                         scaler=scl\n",
    "#                     )\n",
    "#                     df_scores['SMOTE'] = b\n",
    "#                     df_scores['imputer'] = imp\n",
    "#                     df_scores['scaler'] = scl\n",
    "#                     # sort to keep best\n",
    "#                     df_scores.sort_values(\n",
    "#                         by=[primary_eval_metric, secondary_eval_metric], \n",
    "#                         inplace=True, \n",
    "#                         ascending=False\n",
    "#                     )\n",
    "#                     df_scores = df_scores.reset_index()\n",
    "#                     df_scores = df_scores.iloc[:,1:]\n",
    "#                     if df_scores[primary_eval_metric][0] > best_score:\n",
    "#                         best_f1 = df_scores[primary_eval_metric][0]\n",
    "#                         best_cols = df_random_feats.columns\n",
    "#                         df_scores['features'] = str(df_random_feats.columns.tolist())\n",
    "#                         df_scores['trial_num'] = i\n",
    "#                         df_best_scores = pd.concat([df_best_scores, df_scores.iloc[0:1,:]], ignore_index=True)\n",
    "# except KeyboardInterrupt as e:\n",
    "#     print(e)\n",
    "\n",
    "# df_best_scores.sort_values(\n",
    "#     by=[primary_eval_metric, secondary_eval_metric], \n",
    "#     inplace=True, \n",
    "#     ascending=False\n",
    "# )\n",
    "# df_best_scores = df_best_scores.reset_index(drop=True)\n",
    "# print(best_f1)\n",
    "# print(best_cols)\n",
    "# df_best_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized choices for imputer, SMOTE, and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "##### with all setting each trial takes a while ##########\n",
    "##### commenting out options can make bring iteration time down drastically ###########\n",
    "num_trials = 30\n",
    "best_score = 0\n",
    "primary_eval_metric = 'f1-score'\n",
    "secondary_eval_metric = 'recall' \n",
    "\n",
    "best_cols = []\n",
    "df_best_scores = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in tqdm(range(1, num_trials+1)):\n",
    "        df_random_feats = df_cdc_clean.iloc[:,2:]\n",
    "        rand_num_features = random.randint(3, (df_random_feats.shape[1]))\n",
    "        df_random_feats = df_random_feats.sample(n=rand_num_features, axis='columns')\n",
    "        X = df_random_feats\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # SMOTE or not\n",
    "        for b in [random.choice([True, False])]:\n",
    "            # different imputers\n",
    "            for imp in [random.choice([KNNImputer(), SimpleImputer(strategy='mean'), SimpleImputer(strategy='most_frequent')])]:\n",
    "                for scl in [random.choice([RobustScaler(), StandardScaler(), MinMaxScaler(), Normalizer()])]:\n",
    "                    df_scores = baseline_models(\n",
    "                        X_train, \n",
    "                        y_train, \n",
    "                        X_test, \n",
    "                        y_test, \n",
    "                        do_smote=b, \n",
    "                        algo_attempt_list=['bnb', 'gnb', 'lm'],\n",
    "                        grid_search=True,\n",
    "                        cv=5,\n",
    "                        verbose=0,\n",
    "                        imputer=imp,\n",
    "                        scaler=scl\n",
    "                    )\n",
    "                    df_scores['SMOTE'] = b\n",
    "                    df_scores['imputer'] = imp\n",
    "                    df_scores['scaler'] = scl\n",
    "                    # sort to keep best\n",
    "                    df_scores.sort_values(\n",
    "                        by=[primary_eval_metric, secondary_eval_metric], \n",
    "                        inplace=True, \n",
    "                        ascending=False\n",
    "                    )\n",
    "                    df_scores = df_scores.reset_index()\n",
    "                    df_scores = df_scores.iloc[:,1:]\n",
    "                    if df_scores[primary_eval_metric][0] > best_score:\n",
    "                        best_f1 = df_scores[primary_eval_metric][0]\n",
    "                        best_cols = df_random_feats.columns\n",
    "                        df_scores['features'] = str(df_random_feats.columns.tolist())\n",
    "                        df_scores['trial_num'] = i\n",
    "                        df_best_scores = pd.concat([df_best_scores, df_scores.iloc[0:1,:]], ignore_index=True)\n",
    "except KeyboardInterrupt as e:\n",
    "    print(e)\n",
    "\n",
    "df_best_scores.sort_values(\n",
    "    by=[primary_eval_metric, secondary_eval_metric], \n",
    "    inplace=True, \n",
    "    ascending=False\n",
    ")\n",
    "df_best_scores = df_best_scores.reset_index(drop=True)\n",
    "print(best_f1)\n",
    "print(best_cols)\n",
    "df_best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_best_scores.iloc[0,:]['features'])\n",
    "X = df_cdc_clean[ast.literal_eval(df_best_scores.iloc[0,:]['features'])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "baseline_models(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    do_smote=True,\n",
    "    show_confusion_matrix=True,\n",
    "    algo_attempt_list=['lm'],\n",
    "    show_full_report=True,\n",
    "    scaler=MinMaxScaler()\t\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With subset of selected features\n",
    "\n",
    "Logistic Regression model that performed decent. Using this for the trainer.py for API standup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subset = [\n",
    "    'has_health_insurance',\n",
    "    'difficult_doing_daytoday_tasks',\n",
    "    'age_range_first_menstrual_period',\n",
    "    'weight_change_intentional',\n",
    "    'thoughts_you_would_be_better_off_dead',\n",
    "    'little_interest_in_doing_things',\n",
    "    'trouble_concentrating',\n",
    "    'food_security_level_household',\n",
    "    'general_health_condition',\n",
    "    'monthly_poverty_index',\n",
    "    'food_security_level_adult',\n",
    "    'count_days_seen_doctor_12mo',\n",
    "    'has_overweight_diagnosis',\n",
    "    'feeling_down_depressed_hopeless',\n",
    "    'count_minutes_moderate_recreational_activity',\n",
    "    'have_liver_condition',\n",
    "    'pain_relief_from_cardio_recoverytime',\n",
    "    'education_level',\n",
    "    'count_hours_worked_last_week',\n",
    "    'age_in_years',\n",
    "    'has_diabetes',\n",
    "    'alcoholic_drinks_past_12mo',\n",
    "    'count_lost_10plus_pounds',\n",
    "    'days_nicotine_substitute_used',\n",
    "    'age_with_angina_pectoris',\n",
    "    'annual_healthcare_visit_count',\n",
    "    'poor_appetitie_or_overeating',\n",
    "    'feeling_bad_about_yourself',\n",
    "    'has_tried_to_lose_weight_12mo',\n",
    "    'count_days_moderate_recreational_activity',\n",
    "    'count_minutes_moderate_sedentary_activity'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_name = 'Logistic Regression'\n",
    "print(df_best_scores.iloc[0,:]['features'])\n",
    "X = df_cdc_clean[feature_subset]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "my_imputer = SimpleImputer()\n",
    "X_train = my_imputer.fit_transform(X_train)\n",
    "X_test = my_imputer.fit_transform(X_test)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "processing_pipeline = make_pipeline(SimpleImputer(), MinMaxScaler(), LogisticRegression(max_iter=1000, penalty='l2', C=10))\n",
    "\n",
    "\n",
    "processing_pipeline.fit(X_train, y_train)\n",
    "pred_labels  = processing_pipeline.predict(X_test)\n",
    "pred_labels = [x.round() for x in pred_labels]\n",
    "\n",
    "df_algo_cls_rpt = get_classification_report(pred_labels, y_test, algo_name, show_full_report=True)\n",
    "tn, fp, fn, tp = confusion_matrix(pred_labels, y_test).ravel()\n",
    "df_algo_cls_rpt['tp'] = tp\n",
    "df_algo_cls_rpt['fn'] = fn\n",
    "df_algo_cls_rpt['fp'] = fp\n",
    "df_algo_cls_rpt['tn'] = tn\n",
    "df_algo_cls_rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
