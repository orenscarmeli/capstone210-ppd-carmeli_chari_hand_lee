{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get all xpt file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# xpt_file_list = glob.glob('./xpt_data/*.XPT')\n",
    "# print(os.path.basename(xpt_file_list[0]).split('.')[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the html page with the variable codebook for all xpt files\n",
    "# use this to rename the columns to descriptive cols\n",
    "url = 'https://wwwn.cdc.gov/nchs/nhanes/search/variablelist.aspx?Component=Questionnaire&Cycle=2017-2020'\n",
    "page = requests.get(url)\n",
    "\n",
    "# beautiful soup is good for parsing html\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# this is the id for the table on the variable codebook bage\n",
    "tbl = soup.find(\"table\",{\"id\":\"GridView1\"})\n",
    "\n",
    "# get the table and load into a df\n",
    "df_var_mapping = pd.read_html(str(tbl))[0]\n",
    "df_var_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a key value mapping between the variable name and description\n",
    "var_map = dict(zip(\n",
    "    df_var_mapping['Variable Name'], \n",
    "    df_var_mapping['Variable Description']\n",
    "))\n",
    "\n",
    "var_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_xpt_files(folder_path):\n",
    "    \"\"\"Input folder path to read multiple xpt files in folder\n",
    "       Returns dictionary with key: file name, \n",
    "                               value: df\"\"\"\n",
    "    df_dict = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if 'XPT' in os.path.splitext(file_name)[1]:\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_sas(file_path, format='xport')\n",
    "            name = os.path.splitext(file_name)[0]\n",
    "            if df.empty:\n",
    "                raise Exception (f'Empty dataframe from file: {name}')\n",
    "            df_dict[name] = df\n",
    "        else:\n",
    "            print(f'not loading file {file_name}')\n",
    "    return df_dict\n",
    "\n",
    "\n",
    "\n",
    "def full_outer_join(dataframes):\n",
    "    joined_df = None\n",
    "    for df in dataframes.values():\n",
    "        if joined_df is None:\n",
    "            joined_df = df\n",
    "        else:\n",
    "            joined_df = pd.merge(joined_df, df, on='SEQN', how='outer')\n",
    "    return joined_df\n",
    "\n",
    "\n",
    "folder_path = './xpt_data/'\n",
    "dataframes_dict = read_xpt_files(folder_path)\n",
    "df_cdc_joined = full_outer_join(dataframes_dict)\n",
    "df_cdc_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdc_joined.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert bytes and clean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bytes and strip whitespace\n",
    "df_cdc_joined_clean = df_cdc_joined.apply(lambda x: x.str.decode('utf-8').str.strip() if x.dtype == \"object\" else x)\n",
    "# replace empty strings with nan\n",
    "df_cdc_joined_clean = df_cdc_joined_clean.replace('', np.nan)\n",
    "df_cdc_joined_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter to columns we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = '''SEQN\n",
    "FSD652CW\n",
    "HUQ010\n",
    "HUQ030\n",
    "HUQ090\n",
    "DPQ010\n",
    "DPQ020\n",
    "DPQ030\n",
    "DPQ040\n",
    "DPQ050\n",
    "DPQ060\n",
    "DPQ070\n",
    "DPQ080\n",
    "DPQ090\n",
    "DPQ100\n",
    "RXDUSE\n",
    "RXDDAYS\n",
    "RXDRSC1\n",
    "RXDRSC2\n",
    "RXDRSC3\n",
    "RXDRSD1\n",
    "RXDRSD2\n",
    "RXDRSD3\n",
    "RHQ074\n",
    "RHQ076\n",
    "RHD167\n",
    "RHQ171'''.split()\n",
    "cols_to_keep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rename based on the mapping obtained from cdc codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdc_joined_clean_trim = df_cdc_joined_clean[cols_to_keep]\n",
    "df_cdc_joined_clean_trim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rename columns with var descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdc_joined_clean_trim.rename(columns=var_map, inplace=True)\n",
    "df_cdc_joined_clean_trim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick check on stats of selected cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pandas display options using with statement\n",
    "# lets us supress sci notation and see all columns \n",
    "# without messing up your pandas output everywhere\n",
    "with pd.option_context('display.max_columns', None, 'display.float_format', lambda x: '%.3f' % x): # also can do all rows using 'display.max_rows', None, \n",
    "    display(df_cdc_joined_clean_trim.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01ff409f73b03d6519eeb1957ccfce57d615f2ffd1f1b7ba6202370b58e38602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
